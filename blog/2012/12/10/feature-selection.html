<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="ru" lang="ru-ru">
<head>
	 <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
	 <meta http-equiv="content-type" content="text/html; charset=utf-8" />
	 <title>Feature selection в алгоритмах классификации</title>
	 <meta name="author" content="Denis Bazhenov" />
	 <link href="http://feeds.feedburner.com/severe-reality" rel="alternate" title="Severe Reality" type="application/atom+xml" />
	 <link href='http://fonts.googleapis.com/css?family=Open+Sans:300,400,600&subset=latin,cyrillic-ext,cyrillic' rel='stylesheet' type='text/css'>
	 
	 <link rel="openid2.provider" href="https://www.google.com/accounts/o8/ud?source=profiles" > 
	 <link rel="openid2.local_id" href="http://www.google.com/profiles/dotsid" >
	 
	 <!-- syntax highlighting CSS -->
	 <link rel="stylesheet" href="/css/syntax.css" type="text/css" />
	 <!-- Homepage CSS -->
	 <link rel="stylesheet" href="/css/screen.css" type="text/css" media="screen, projection" />
	 <link rel="stylesheet" href="http://yandex.st/highlightjs/6.1/styles/idea.min.css">

	<script src="http://code.jquery.com/jquery-1.7.1.min.js"></script>
</head>
<body>

	<div class="site">
		
			<header>
				<div class="content">
					<a href="/">Суровая реальность</a>
				</div>
			</header>
		

		<div class="post content">
	<h1>Feature selection в алгоритмах классификации</h1>
	<div class="meta">
		<span class="date">10 December 2012</span>
		<span class="tags">
			
				<a href="/tags.html#algorithms">algorithms</a>
			
				<a href="/tags.html#math">math</a>
			
		</span>
		
	</div>
	
	
	<p>Существует один очень простой и эффективный способ улучшения алгоритмов классификации, который называется <a href="http://en.wikipedia.org/wiki/Feature_selection">feature selection</a> (выбор классификационных признаков). Этот метод позволяет при построении модели выбрать только самые показательные признаки (например, слова) и отсеять остальные.</p>

<p>Что такое показательные признаки? Если мы говорим о задаче классификации текстовых документов, то это слова которые несут информацию о классе к которому относится документ. Например, в контексте автомобильной тематики слово &ldquo;Nissan&rdquo;, скорее всего будет показательным признаком, а вот слово &ldquo;новый&rdquo; вряд ли. Использование для классификации не всех слов, а только показательных дает несколько преимуществ.</p>

<p>Во-первых, feature selection позволяет существенно уменьшить количество параметров модели (используемых для классификации слов), и как следствие снижает требования к объему памяти требуемой для классификации.</p>

<p>Во-вторых, feature selection может повысить точность алгоритма за счет удаления из модели слов с низким соотношением сигнал/шум. Представьте, что слово &ldquo;аскетичный&rdquo; встретилось в обучающей выборке 3 раза, – 1 раз в рамках класса &ldquo;Авто&rdquo; и 2 раза в рамках класса &ldquo;Одежда&rdquo;. Формально оно говорит в пользу класса &ldquo;Одежда&rdquo;, но вряд ли это слово можно считать хорошим классификационным признаком. Скорее всего, перевес в сторону одежды это случайность.</p>

<p>Но <em>сам факт наличия такого слово в обучающей выборке не случайность</em>. Это следствие <a href="http://ru.wikipedia.org/wiki/Закон_Ципфа">закона Зипфа</a> (Zipf&rsquo;s law), который описывает распределение частот слов в натуральном языке. Простым языком это можно описать следующим образом, если вы возьмете любой достаточно большой корпус документов и посчитаете сколько в нем слов встречающихся ровно 1 раз, 2 раза, 3 раза и т.д., то окажется что большинство слов встречаются 1 раз. Это не должно быть большим сюрпризом, – в повседневной жизни мы используем довольно небольшое количество слов (высокочастотники), а большую часть слов мы практически не используем (низкочастотники).</p>

<h2 id="mutual-information">Mutual Information</h2>

<p>В этой заметке я опишу один, пожалуй самый простой способ оценки показательности классификационных признаков, – <a href="http://nlp.stanford.edu/IR-book/html/htmledition/mutual-information-1.html">метод взаимной информации</a> (Mutual Information). Идея метода очень проста. Зная как часто слово употребляется в пределах документов класса и за его пределами, мы можем сказать насколько статистически сильно связаны слово и класс.</p>

<p>Для того чтобы рассчитать численное значение взаимной информации необходимо составить матрицу цитирумости. Матрица цитируемости – это матрица 2x2 которая показывает взаимоотношение конкретного слова с конкретным классов. Возьмем, к примеру слово &ldquo;Toyota&rdquo; и класс &ldquo;Авто&rdquo;.</p>

<table align="center">
	<tr>
		<th />
		<th>C<sub>Авто</sub>=1</th>
		<th>C<sub>Авто</sub>=0</th>
	</tr>
	<tr>
		<th>W<sub>Toyota</sub>=1</th>
		<td>N<sub>11</sub>=65 342</td>
		<td>N<sub>10</sub>=143</td>
	</tr>
	<tr>
		<th>W<sub>Toyota</sub>=0</th>
		<td>N<sub>01</sub>=45 342</td>
		<td>N<sub>00</sub>=897 657</td>
	</tr>
</table>

<p>Из этой матрицы видно что слово &ldquo;Toyota&rdquo; было встречено в 65 342 документах в контексте класса &ldquo;Авто&rdquo;, а также в 143 документах за переделами класса &ldquo;Авто&rdquo;. Имея на руках такую матрицу мы можем рассчитать взаимную информацию по формуле:</p>

<script type="math/tex; mode=display"> MI =
\frac{N_{11}}{N} \log_2{ \frac{N N_{11}}{N_{1.} N_{.1}} } +
\frac{N_{01}}{N} \log_2{ \frac{N N_{01}}{N_{0.} N_{.1}} } + 
\frac{N_{10}}{N} \log_2{ \frac{N N_{10}}{N_{1.} N_{.0}} } +
\frac{N_{00}}{N} \log_2{ \frac{N N_{00}}{N_{0.} N_{.0}} } </script>

<p>где, <script type="math/tex"> N </script> — сумма всей матрицы, <script type="math/tex"> N_{0.} = N_{00} + N_{01} </script>, <script type="math/tex"> N_{.1} = N_{01} + N_{11} </script> и т.д.</p>

<p>Взаимная информация всегда находится в диапазоне от нуля до единицы. Чем выше значение, тем сильнее связь между наличием/отсутствием слова и наличием/отсутствием класса. Рассчитав взаимную информацию для всех пар слово-класс мы можем оставить для каждого класса первые N слов, объединить эти слова в общий словарь и теперь только их использовать для классификации. Количество слов необходимых для оптимальной классификации зависит от конкретной задачи и его необходимо подбирать эмпирически, постоянно проверяя результаты на тестовой выборке.</p>

<p>На тех задач на которых я тестировал этот метод, он давал прирост точности от 3 до 10%. В Introduction to Infromation Retrieval указано что на практике возможен прирост в десятки процентов по F<sub>1</sub><sup id="fnref:ref-mi-performance"><a href="#fn:ref-mi-performance" rel="footnote">1</a></sup>. Все зависит от вашей конкретной задачи, а также классификационного алгоритма.</p>

<div class="footnotes">
  <ol>
    <li id="fn:ref-mi-performance">
      <p><a href="http://nlp.stanford.edu/IR-book/html/htmledition/mutual-information-1.html#fig:mccallum">Introduction to Information Retrieval, 2008 Cambridge University Press</a><a href="#fnref:ref-mi-performance" rel="reference">&#8617;</a></p>
    </li>
  </ol>
</div>


	<div class="bar">
		<div class="g-plusone" data-size="medium"></div>
		<a href="https://twitter.com/share" class="twitter-share-button"
			data-url="http://bazhenov.me/blog/2012/12/10/feature-selection.html"
			data-via="denis_bazhenov" data-lang="en">Tweet</a>

		<a href="https://twitter.com/denis_bazhenov" class="twitter-follow-button"
			data-show-count="false">Follow</a>
	</div>

	<div id="disqus_thread"></div>
	<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>

<!-- Google +1 button -->
<script type="text/javascript">
	(function() {
		var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
		po.src = 'https://apis.google.com/js/plusone.js';
		var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
	})();
</script>

<!-- Twitter buttons -->
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src="//platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>

<!-- Disqus -->
<script type="text/javascript">
	/* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
	var disqus_shortname='severe-reality';
	var disqus_developer=false;

	/* * * DON'T EDIT BELOW THIS LINE * * */
	(function() {
		var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
		dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
		(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	})();
</script>

		<footer>
			<div class="content">
				<a href="http://feeds.feedburner.com/severe-reality">RSS Subscribe</a>
					|
				<a href="mailto:dotsid@gmail.com">Email</a>
			</div>
		</footer>
					
	</div>

	<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
	
	<script src="http://yandex.st/highlightjs/6.1/highlight.min.js"></script>
	<script>
	$(document).ready(function() {
		$('pre.code code').each(function(i, e) {hljs.highlightBlock(e, '  ')});
	});
	</script>
	<script type="text/javascript">
		MathJax.Hub.Config({
			tex2jax: {
				inlineMath: [['$','$'], ['\\(','\\)']],
				processEscapes: true
			}
		});
	</script>
	
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-31484732-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>

</body>
</html>