<?xml version="1.0"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Суровая реальность</title>
    <link>http://bazhenov.me</link>
    <atom:link href="http://bazhenov.me/rss.xml" rel="self" type="application/rss+xml" />
    <description>Суровая реальность</description>
    <language>ru-ru</language>
    <pubDate>Fri, 04 May 2012 18:12:49 +1100</pubDate>
    <lastBuildDate>Fri, 04 May 2012 18:12:49 +1100</lastBuildDate>
    
    <item>
      <title>Один на миллион</title>
      <link>http://bazhenov.me/blog/2012/04/16/one-in-a-million.html</link>
      <pubDate>Mon, 16 Apr 2012 00:00:00 +1100</pubDate>
      <author>dotsid@gmail.com (Denis Bazhenov)</author>
      <guid>http://bazhenov.me/blog/2012/04/16/one-in-a-million</guid>
      <description>&lt;p&gt;Вам наверное приходилось слышать что-то вроде: &amp;ldquo;Этого не может быть. Вероятность этого менее одной миллионной&amp;rdquo;. В бытовом понимании одна миллионная это некая несвершимая вероятность. Другими словами, этого просто не может произойти. Но насколько это вeрятное событие, если вы повторите эксперимент миллион раз? Конечно, вероятность наблюдать событие растет если вы повторяете эксперимент много раз подряд. Но все равно мы зачастую подсознательно пытаемся игнорировать такие события считая их невероятными.&lt;/p&gt;

&lt;!-- excerpt --&gt;

&lt;p&gt;Тем не менее, в современных Интернет-системах которые обрабатывают миллионы запросов в сутки &lt;em&gt;не заметить&lt;/em&gt; в течение дня событие с вероятностью в одну миллионную довольно сложно. И вот почему. Вероятность что интересующее нас событие (с исходной вероятностью &lt;code&gt;1/n&lt;/code&gt;) не проявит себя ни в одном из &lt;code&gt;n&lt;/code&gt; независимых экспериментов равно:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;(1-\frac{1}{n})^n&lt;/script&gt;

&lt;p&gt;В этой формуле $\frac{1}{n}$ — вероятность события которое реализуется в одном эксперименте из &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt;. &lt;script type=&quot;math/tex&quot;&gt;1-\frac{1}{n}&lt;/script&gt; соответственно вероятность что это событие &lt;em&gt;не реализуется&lt;/em&gt; в ходе эксперимента. Ну и не тяжело догодаться что $(1-\frac{1}{n})^n$ это вероятность с которой это событие &lt;em&gt;не реализуется в ходе &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; независимых экспериментов&lt;/em&gt;. Для n = 1 000, если вы его подставите в формулу, итоговое значение вероятности составит 0.368 или 36.8%. Для n = 1 000 000, значение вероятности составит&amp;hellip; те же самые 36.8%! &lt;em&gt;Редкость события всегда уравновешивается частотой повторения испытаний.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Обоснование этого возможно контринтуитивного результата кроется во &lt;a href=&quot;http://ru.wikipedia.org/wiki/Замечательные_пределы#.D0.92.D1.82.D0.BE.D1.80.D0.BE.D0.B9_.D0.B7.D0.B0.D0.BC.D0.B5.D1.87.D0.B0.D1.82.D0.B5.D0.BB.D1.8C.D0.BD.D1.8B.D0.B9_.D0.BF.D1.80.D0.B5.D0.B4.D0.B5.D0.BB&quot;&gt;втором замечательном пределе&lt;/a&gt;, который большинству из нас преподавали в ходе курса высшей математики.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\lim_{n \to +\infty}(1+\frac{1}{n})^n = e&lt;/script&gt;

&lt;p&gt;Второй замечательный предел интенсивно используется при решении дифференциальных уравнений, но нас интересует одно из следствий этого предела.&lt;/p&gt;

&lt;p&gt;Этот предел говорит нам о том что при растущем &lt;code&gt;n&lt;/code&gt;, значение выражения &lt;script type=&quot;math/tex&quot;&gt;(1-\frac{1}{n})^n&lt;/script&gt; стремится к значению &lt;script type=&quot;math/tex&quot;&gt;\frac{1}{e}&lt;/script&gt;, которое является той самой константой приблизительно равной 0.368.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Я не буду здесь приводить доказательство этого следствия второго замечательного предела. Предел разумного количества формул на один пост достигнут :).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Теперь давайте соберем все это вместе. Предположим что у вас есть некий баг (скажем, race condition в многопоточном приложении), который воспроизводится с вероятностью один на миллион. Фактически что говорит этот предел – если вы обслужите за день миллион запросов то вероятность того что этот баг не порявит себя ни в одном из запросов ~37%. То есть с вероятностью ~63% этот баг даст о себе знать &lt;em&gt;хотя бы один раз&lt;/em&gt; за сутки.&lt;/p&gt;

&lt;p&gt;Из этого можно сделать еще один вывод. Чем больше запросов вы обрабатываете за сутки, тем более редкие явления вы будете наблюдать в течение суток. 100 000 запросов в сутки? Тогда вероятность &lt;script type=&quot;math/tex&quot;&gt;\frac{1}{1 000 00}&lt;/script&gt; для вас не редкость. 10 000 000? Тогда и одной десятимиллионной вас не удивишь.&lt;/p&gt;

&lt;p&gt;Да пребудет с вами нормальное распределение!&lt;/p&gt;

</description>
    </item>
    
    <item>
      <title>О высокой нагрузке</title>
      <link>http://bazhenov.me/blog/2012/02/26/highload.html</link>
      <pubDate>Sun, 26 Feb 2012 00:00:00 +1100</pubDate>
      <author>dotsid@gmail.com (Denis Bazhenov)</author>
      <guid>http://bazhenov.me/blog/2012/02/26/highload</guid>
      <description>&lt;p&gt;В последнее время все чаще говорят о &lt;em&gt;высоконагруженных&lt;/em&gt; приложениях. Нельзя не заметить что это теперь очень популярная, можно даже сказать модная, область знаний. Сам же термин &amp;ldquo;высоконагруженная система&amp;rdquo; при этом не имеет в нашей отрасли четкого определения. В этой заметке я хочу привести свои рассуждения по этому вопросу. Я не ставлю перед собой цель дать исчерпывающее определение этого термина. Моя цель, предоставить читателю ключевую информацию о системах такого рода, которая определяет стиль мышления при работе с ними.&lt;/p&gt;

&lt;!-- excerpt --&gt;

&lt;p&gt;Итак, что такое высоконагруженная система? Ответ на этот вопрос стоит начать с описания качественных свойств такого рода систем.&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;Традиционные качества высоконагруженной системы&lt;/h2&gt;
&lt;p&gt;Как правило, к таким качествам относят большое количество пользователей и данных. В целом это правда, но тут есть несколько загвоздок:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;это не вся правда;&lt;/li&gt;
  &lt;li&gt;приведенные факторы являются количественными, а не качественными.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ниже на основании предпосылки &amp;ldquo;много пользователей, много данных&amp;rdquo; я сформирую список качественных факторов присущих высоконагруженным системам. Начнем с самого простого.&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;Многопользовательская система&lt;/h3&gt;
&lt;p&gt;Конечно же высоконагруженное приложение в первую очередь является многопользовательским. То есть в один момент времени с ним работает более чем один человек. Сейчас, в эру стремительного развития Интернета, это тысячи и сотни тысяч человек.&lt;/p&gt;

&lt;p&gt;Устойчивая ассоциация высоконагруженных систем с большим количеством пользователей в нашей индустрии появилась давным давно. Ничего принципиально неверного в такой связи нет. Но если высокая нагрузка подразумевает большое количество пользователей, то большое количество пользователей совсем не обязательно подразумевает высоконагруженную систему.&lt;/p&gt;

&lt;p&gt;Если посмотреть на статистику Московского метрополитена за 2010 год, то окажется что средняя часовая нагрузка на систему максимальна в диапазоне от 8 до 9 часов утра&lt;sup id=&quot;fnref:ref-metro-stat&quot;&gt;&lt;a href=&quot;#fn:ref-metro-stat&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. За этот час через турникеты проходят приблизительно 720 тысяч человек. Что порождает необходимость не менее 200 раз в секунду проверять статус предъявленных проездных и принимать решение о пропуске того или иного человека через турникет. В Интернете существует масса высоконагруженных ресурсов с подобными показателями пропускной способности. Например, статистика по StackOverflow за тот же 2010-й год показывает что их средняя пропускная способность находится в диапазоне 100-150 хитов в секунду&lt;sup id=&quot;fnref:ref-stackoverflow-stat&quot;&gt;&lt;a href=&quot;#fn:ref-stackoverflow-stat&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;Определенно у метрополитена более высокие требования к пропускной способности. Но значит ли это что Московский метрополитен можно считать более &amp;ldquo;высоконагруженным&amp;rdquo; чем StackOverflow? Вряд ли, в частности потому что эти две системы оперируют несравнимыми объемами информации, о чем мы поговорим позже.&lt;/p&gt;

&lt;p&gt;Я намерено в обоих случаях привел оценку пропускной способности, так как она дает больше информации о нагрузке чем количество пользователей системы. Две разные системы могут подталкивать пользователей к разным паттернам их использования. Это может приводить к абсолютно разным требованиям по пропускной способности для этих систем. Пропускная способность точнее описывает количество работы которую должна уметь выполнять система в единицу времени.&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;Распределенная система&lt;/h3&gt;
&lt;p&gt;Высоконагруженные системы являются системами распределенными, то есть работают более чем на одном сервере. Зачастую это десятки и сотни серверов. Требование распределенности вытекает из следующих причин:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;необходимости обрабатывать возрастающие объемы данных;&lt;/li&gt;
  &lt;li&gt;необходимости &amp;ldquo;живучести&amp;rdquo; системы в случаях отказа части серверов.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Но обо всем по порядку…&lt;/p&gt;

&lt;p&gt;Я наверное не ошибусь если скажу что большинство высоконагруженных приложений являются Интернет-приложениями (позже мы еще вернемся к состоятельности этой гипотезы). А отличительной особенностью современного Интернета основанного на концепции &lt;a href=&quot;http://ru.wikipedia.org/wiki/Веб_2.0&quot;&gt;Web 2.0&lt;/a&gt; является тот факт, что сами пользователи генерируют данные, которые они сами же в итоге и потребляют. Это приводит к тому, что чем больше у вас пользователей, тем больше потенциальный объем хранимых данных.&lt;/p&gt;

&lt;p&gt;Требование обработки больших объемов данных может существенно осложнить жизнь. Под &amp;ldquo;большим объемом&amp;rdquo; я подразумеваю такой объем информации, который не может эффективно обработать одна машина. В большинстве случаев, это объем превышающий объем доступной на сервере оперативной памяти. То есть приходится тем или иным образом распределять данные между несколькими машинами, каждая из которых обрабатывает свой небольшой кусочек данных, но делает это эффективно, без page fault&amp;rsquo;ов (не используя swap) и прочих неприятностей. Необходимость эффективной обработки данных диктуется другим очень важным качеством высоконагруженных систем, – интерактивностью, о котором будет сказано ниже.&lt;/p&gt;

&lt;p&gt;Но большие объемы данных – это не все. Ко всему к этому хочется чтобы система работала в режиме 24x7 без остановок и перерывов. Но вот незадача, любое даже самое надежное оборудование иногда выходит из строя. Встает естественная задача обеспечения доступности системы в случаях отказа оборудования. &lt;/p&gt;

&lt;p&gt;Тут мы вступаем в область знания распределенных систем, эксплуатация которых редко бывает безоблачной, даже когда вы используете готовые решения. Тем не менее распределенные системы, не смотря на сложность их разработки и поддержки, пожалуй единственный подход позволяющий обеспечить вышеизложенные требования в полной мере.&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;Позитивная динамика по пользователям и данным&lt;/h3&gt;
&lt;p&gt;Если ваше приложение представляет хоть какой-то интерес, то даже если ничего не делать, ваша аудитория будет расти просто с ростом аудитории Интернета. Поэтому характерной чертой высоконагруженных систем является не просто большое количество пользователей, но и &lt;em&gt;позитивная динамика&lt;/em&gt; количества пользователей.&lt;/p&gt;

&lt;p&gt;В контексте реалий Web 2.0 растущее количество пользователей может привести к тому, что &lt;em&gt;такую же позитивную динамику вы будете иметь и по данным&lt;/em&gt;. Поэтому в контексте высоконагруженных систем корректней говорить не о &lt;em&gt;большом&lt;/em&gt;, а о &lt;em&gt;растущем&lt;/em&gt; количестве пользователей и данных.&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;Интерактивность&lt;/h3&gt;
&lt;p&gt;И тут мы подходим к своеобразной финальной ноте в аккорде качеств highload систем, если позволите так выразиться. Интерактивность – одно из основополагающих качеств высоконагруженной системы. Интерактивность подразумевает, что пользователь после того как послал запрос сидит и ждет ответа, а люди как известно ждать не любят. При этом большинство Интернет-приложений о которых мы говорим не являются критическими важными в жизни людей. Twitter, Flickr, Facebook и т.д. это все круто конечно, но если они будут отвечать непомерно долго, я найду чем занятся еще. Наша жизнь от них не зависит (прогрессирующие формы задротства у некоторых особо аддиктивных индивидов не в счет), а это значит что эти приложения должны занимать минимум нашего времени. То есть отвечать за приемлимое время. Это контрастирует, например, с системами пакетной обработки данных, в которых время ответа системы вторично.&lt;/p&gt;

&lt;p&gt;Из этого правила безусловно есть исключения. Представьте что вы только что совершили покупку в Интернете сообщив свою платежную информацию третьим лицам. Скорее всего вы дождетесь ответа системы, даже если она будет отвечать дольше минуты. Но как известно исключение из правила лишний раз подверждает само правило.&lt;/p&gt;

&lt;h2 id=&quot;section-5&quot;&gt;Управление ресурсами&lt;/h2&gt;
&lt;p&gt;Качество интерактивности очень важно для понимания сути высоконагруженных приложений, потому что по вышеобозначенным причинам разрабатывая такую систему вы должны быть уверены вот в чем:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Каждый раз когда приложение получает очередной запрос, у него  должно быть достаточно свободных ресурсов (CPU, память, диск, сеть) для обработки запроса за приемлимое время.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Возможно это и звучит тривиально, но именно данное требование приводит нас к основному посылу данной заметки:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Контроль за ресурсами является неотъемлимой частью работы с высоконагруженным проектом.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Необходимо также учитывать тот факт, что из-за позитивной динамики &lt;em&gt;свободных ресурсов становится меньше с течением времени&lt;/em&gt;. В этом заключается &amp;ldquo;парадокс&amp;rdquo; высоконагруженных систем. Если вы возьмете высоконагруженный проект и заморозите его разработку (отправите всех разработчиков в бессрочный отпуск), то &lt;em&gt;рано или поздно он перестанет работать&lt;/em&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Высоконагруженная система – это интерактивная распределенная система которая требует постоянного контроля за собственными ресурсами. В противном случае она перестает работать.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Это противоречит обывательскому опыту. Как может само по себе поломаться то, чего не меняли? У программного кода нет срока годности. Причина в том, что со временем системе просто перестанет хватать ресурсов. А нехватка ресурсов провоцируется факторами, часть из которых мы уже рассмотрели:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;рост аудитории;&lt;/li&gt;
  &lt;li&gt;рост объема данных;&lt;/li&gt;
  &lt;li&gt;изменения паттернов поведения аудитории, в том числе и сезонные.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Если посмотреть темы докладов на конференциях посвященных тематике разработки высоконагруженных систем (например, тот же &lt;a href=&quot;http://highload.ru/&quot;&gt;highload&lt;/a&gt;), то большинство тем с которыми выступают докладчики можно свести к двум основополагающим направлениям:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;как решать существующие задачи используя меньше ресурсов (практически все NoSQL БД, неблокирующий I/O, оптимизация и тюнинг);&lt;/li&gt;
  &lt;li&gt;как имея больше ресурсов решать пропорционально больший объем задач (message queueing, распределенные вычисления, распределенные БД, параллелизм).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Эту дихотомию я уже затрагивал ранее в заметке &lt;a href=&quot;/blog/2009/06/28/performance-versus-scalability.html&quot;&gt;Performance vs. Scalability&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Фактически речь на таких конференциях идет в основном о различных способах адекватного управления аппаратными ресурсами в контексте баз данных, языков программирования, операционных систем, алгоритмов, моделей ввода/вывода, вычислительных парадигм и т.д.&lt;/p&gt;

&lt;p&gt;Просто подумайте над этим. Большая часть пропогандируемых в настоящее время баз данных под эгидой NoSQL, не предоставляет качественно новых возможностей для разработчиков. Реляционная модель позволяет относительно легко все это реализовать не выходя за рамки одной парадигмы. В этом, я полагаю, и заключается одна из причин почему реляционки приобрели такую популярность и до сих остаются самым распространенным типом БД.
Так называемые, пост-реляционные базы данных не являются инструментом для решения качественно новых задач, всего лишь инструментом для более эффективного решения существующих. Именно важность эффективной траты ресурсов стала катализатором популярности NoSQL тематики.&lt;/p&gt;

&lt;h2 id=&quot;section-6&quot;&gt;Высоконагруженный проект – это Интернет приложение&lt;/h2&gt;
&lt;p&gt;Если исходить из того что неотъемлемой частью высоконагруженного проекта является постоянный рост данных и аудитории, то становится понятно почему высоконагруженные проекты – это поголовно Интернет приложения.&lt;/p&gt;

&lt;p&gt;В реальной жизни всегда есть некий предел, который не позволяет использовать систему все возрастающему количеству людей. В том же метрополитене человеку требуется некоторое время, чтобы пройти через турникет. Исходя из этого времени, а также общего количества турникетов можно достаточно точно расчитать верхний предел возможной нагрузки. Выглядит очень невероятным чтобы за секунду через один турникет могло пройти 10 человек.&lt;/p&gt;

&lt;p&gt;В сфере High Performance Computations приложения могут выполнять просто гигансткое количество операций в единицу времени. Больше чем любое Интернет-приложение. Но это количество зависит только от объема входных данных, а также алгоритма обработки (например, от точности моделирования, если речь идет о моделировании динамических систем). Тяжело придумать причину почему нагрузка на такую систему может вырасти сама по себе без вмешательства персонала ее сопровождающего.&lt;/p&gt;

&lt;p&gt;Похоже, что Интернет-приложения это единственная сфера в которой нагрузка есть переменная не имеющая верхнего предела.&lt;/p&gt;

&lt;h2 id=&quot;highload-&quot;&gt;Работая в Highload проекте&lt;/h2&gt;
&lt;p&gt;Но не стоит возводить данный тип проектов на какой-то особый пьедестал. Highload проект это в первую очередь такой же самый проект как и все остальные. Проект в котором бывают и гонки за фичами и deadline&amp;rsquo;ы и сложности межличностных отношений и все прочие &amp;ldquo;прелести&amp;rdquo; процесса разработки ПО. Но говоря о &amp;ldquo;высоконагруженной составляющей&amp;rdquo; проекта, работа над ней сводится к тому, что постоянно приходится искать ответы на ресурсно-ориентированные вопросы:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;какие bottleneck&amp;rsquo;и есть в системе по ресурсам и как их устранить?&lt;/li&gt;
  &lt;li&gt;каков запас системы по ресурсам учитывая естественный рост аудитории/данных?&lt;/li&gt;
  &lt;li&gt;что делать при нехватке того или иного ресурса? (например, можно за счет RAM сэкономить CPU).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Не удивительно что в такого рода проектах гигантское значение имеет система мониторинга. Она предоставляет массу информации для ответа на такого рода вопросы. Сопровождать и развивать высоконагруженный проект без мониторинга хотя бы основных метрик по всему серверному парку это безрассудство.&lt;/p&gt;

&lt;p&gt;Это приводит нас к cписку первостепенных задач которые стоят перед разработчиками в контексте высокой нагрузки:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;создание инфраструктуры предоставляющей качественную обратную связь по утилизации аппаратных ресурсов системы (мониторинг, self-аудит приложений);&lt;/li&gt;
  &lt;li&gt;определение звеньев системы нуждающихся в масштабировании в ближайшем времени и выбор стратегии масштабирования этих звеньев; &lt;/li&gt;
  &lt;li&gt;определение toolbox&amp;rsquo;а позволяющего решать типовые задачи эффективно по аппаратным ресурсам (базы данных, очереди сообщений, языки программирования, библиотеки и т.д.).&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-7&quot;&gt;В состоянии гонки&lt;/h2&gt;
&lt;p&gt;У вас как у инженера нет прямого влияния на количество пользователей и есть опосредованое влияние на объемы данных. В конце концов, чем больше данных и чем шире аудитория, тем лучше для бизнеса. Больше пользователей – больше возможностей для монетизации. Больше данных – больше конкурентное преимущество, а так же потенциально более высокие темпы роста проекта. Необходимо смирится с непрерывным ростом этих двух метрик.&lt;/p&gt;

&lt;p&gt;Что же остается? Не так много на самом деле. Сделать так чтобы возможности системы были всегда на шаг впереди ее потребностей.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:ref-metro-stat&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://www.mosmetro.ru/documents/11931/2010.pdf&quot;&gt;Московский Метрополитен 2010: Основные показатели работы метрополитена&lt;/a&gt;&lt;a href=&quot;#fnref:ref-metro-stat&quot; rel=&quot;reference&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:ref-stackoverflow-stat&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://msug.vn.ua/Posts/Details/4149&quot;&gt;Microsoft User Group Community: Немного статистики от StackOverflow за 2010 год&lt;/a&gt;&lt;a href=&quot;#fnref:ref-stackoverflow-stat&quot; rel=&quot;reference&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Deploy и прочие неприятности</title>
      <link>http://bazhenov.me/blog/2011/06/10/deploy.html</link>
      <pubDate>Fri, 10 Jun 2011 00:00:00 +1100</pubDate>
      <author>dotsid@gmail.com (Denis Bazhenov)</author>
      <guid>http://bazhenov.me/blog/2011/06/10/deploy</guid>
      <description>&lt;p&gt;В продолжение &lt;a href=&quot;/blog/2011/04/09/build.html&quot;&gt;предыдущего поста&lt;/a&gt; хочу немного рассказать о том как у нас происходит deploy. В прошлый раз мы закончили на том что артефакт доставлен на production и готов к развертыванию. Начинается самое интересное, процесс деплоя.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;Но для начала надо немного описать платформу на которую мы деплоим наши приложения. В качестве servlet-container&amp;rsquo;а мы используем &lt;a href=&quot;http://jetty.codehaus.org/jetty/&quot;&gt;Jetty&lt;/a&gt;. Есть два основных типа приложений, которые мы пишем и сопровождаем: web-приложения, которые имеют некий web-интерфейс (это может быть как UI, так и REST интерфейс), а также background сервисы, которые как правило работают асинхронно (мы активно используем &lt;a href=&quot;http://activemq.apache.org/&quot;&gt;ActiveMQ&lt;/a&gt;). И здесь нужно подметить первую особенность, мы используем Jetty для обоих типов приложений. Это может показатся странным, так как для background-сервисов мы получаем явный overhead связанный с запуском и работой servlet-container&amp;rsquo;а. Но этот overhead просто мизерный по сравнению с тем какие плюсы мы получаем. А именно:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;единые утилиты управления lifecycle&amp;rsquo;ом приложения вне зависимости от его типа (старт, останов, перезапуск);&lt;/li&gt;
  &lt;li&gt;стандартные способы задания конфигурации приложения вне зависимости от его типа;&lt;/li&gt;
  &lt;li&gt;стандартные форматы распространения приложения вне зависимости от его типа (в нашем случае &lt;code&gt;.war&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Вобщем, стандартизация на лицо.&lt;/p&gt;

&lt;p&gt;У нас своя сборка Jetty в которой кроме самого Jetty, есть еще несколько часто используемых нами библиотек (например: &lt;code&gt;slf4j&lt;/code&gt;, &lt;code&gt;logback&lt;/code&gt;, &lt;code&gt;mysql&lt;/code&gt; драйвер, библиотеки connection pooling&amp;rsquo;а и некоторые другие). Сборка представлена в виде rpm пакета, что позволяет очень быстро подготавливать новую машину: &lt;code&gt;yum install jdk jetty&lt;/code&gt;, готово.&lt;/p&gt;

&lt;p&gt;Вас может удивило почему мы ставим на production машины JDK, а не JRE. Это связано с наличием в JDK очень полезных для диагностики утилит, таких как: &lt;code&gt;jmap&lt;/code&gt;, &lt;code&gt;jstack&lt;/code&gt;, &lt;code&gt;jvisualvm&lt;/code&gt; и других. Это выгодно отличает платформу Java от множества других, &amp;ndash; масса утилит для диагностики, которые в большинстве случаев позволяют довольно быстро понять что не так с приложением.&lt;/p&gt;

&lt;p&gt;Деплой приложения состоит из следующих шагов:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;распространение бинарника с приложением, а также конфигурации на целевые машины;&lt;/li&gt;
  &lt;li&gt;перезапуск servlet container&amp;rsquo;а;&lt;/li&gt;
  &lt;li&gt;deployment тестирование.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Естественно второй и третий шаг выполняются для всех машин по очереди.&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;Распространение артефакта и конфигурации&lt;/h2&gt;
&lt;p&gt;Тут все просто, &lt;code&gt;scp&lt;/code&gt; доставляет файлы на каждую машину по очереди и ложит каждый в нужное место. Доставляются артефакты, а также конфигурационные файлы.&lt;/p&gt;

&lt;h3 id=&quot;servlet-container&quot;&gt;Перезапуск servlet container&amp;rsquo;а&lt;/h3&gt;
&lt;p&gt;Мы не используем hot redeploy, так как он вызывает ряд проблем. В частности, небезизвестную &lt;a href=&quot;http://www.jroller.com/agileanswers/entry/preventing_java_s_java_lang&quot;&gt;OutOfMemoryError: PermGen&lt;/a&gt;. Для перезапуска используются скрипты входящие в стандартную поставку Jetty с некоторыми несущественными дополнениями.&lt;/p&gt;

&lt;h3 id=&quot;deployment-&quot;&gt;Deployment тестирование&lt;/h3&gt;
&lt;p&gt;Этот момент стоит описать поподробнее. После того как Jetty запустился было бы неплохо проверить что приложение способно выполнять основные функции. Тот кто деплоит приложение может опечататься в конфигурации, системные администраторы могут забыть &amp;ldquo;пропилить дырку&amp;rdquo; в firewall&amp;rsquo;е для необходимого приложению сервиса, мало ли что еще может произойти.&lt;/p&gt;

&lt;p&gt;Задача deployment тестирования проверить что у приложения есть доступ ко всем необходимым сервисам для того чтобы оно выполняло свою работу. Это могут быть базы данных, очереди сообщений, сетевые файловые системы и другое middleware ПО. К счастью для нас, Spring Beans контейнер практически все делает за нас. Если во время инициализации контейнера (частью которого являются подключения к БД и т.д.) происходит ошибка, об этом легко узнать послав &lt;code&gt;GET&lt;/code&gt; запрос на любой url, который обрабатывается непосредственно spring&amp;rsquo;ом. У нас есть соглашение что url &lt;code&gt;/status&lt;/code&gt; не занимается приложением и служит для deployment тестирования. Этот url также сообщает какая версия приложения запушена в данный момент. Таким образом, deploy скрипт после того как перезапускает servlet container начинает опрашивать приложение. Если приложение возвращает 200-й статус код, то можно переходить к обновлению следующей машины. Если нет, то процесс деплоя считается неуспешным и прерывается. Тот кто делает deploy может инициировать процедуру отката. Откат мы делаем руками, так как процент &amp;ldquo;битых&amp;rdquo; релизов у нас не велик и смысла автоматизировать эту процедуру пока что смысла нет.&lt;/p&gt;

&lt;h3 id=&quot;rollout--&quot;&gt;Rollout распределенных приложений&lt;/h3&gt;
&lt;p&gt;Когда приложение запущено в нескольких экземплярах (на нескольких машинах), то после запуска приложения на одном ноде имеет смысл немного подождать прежде чем переходить к следующей машине. Здесь играют свою роль как особенности приложения, так и особенности платформы. Java, как русские &amp;ndash; &amp;ldquo;долго запрягает, но быстро едет&amp;rdquo; (начальная загрузка байт кода, создание пула соединений, JIT компилятор etc). Нас такой tradeoff вполне устраивает, поэтому наш deploy скрипт может быть сконфигурирован таким образом, чтобы давать только что запущенному ноду &amp;ldquo;разогреться&amp;rdquo; перед тем как принять на себя нагрузку его еще не обновленных коллег. Как правило, 3-5 секунд достаточно.&lt;/p&gt;

&lt;p&gt;Деплой на несколько машин (особенно учитывая их &amp;ldquo;разогрев&amp;rdquo;) порождает интересную проблему. Во время обновления кластера, на нем работает &lt;em&gt;две версии приложения&lt;/em&gt;. Некоторых людей этот факт ставит в ступор. Они не могут ужиться с тем, что у приложения в любой момент времени нет строго определенной версии.&lt;/p&gt;

&lt;p&gt;Суровая реальность заключается в том, что требование работать одновременно в &amp;ldquo;нескольких версиях&amp;rdquo; порождается природой web-приложений. Мы стремимся к тому чтобы наше система всегда была online. Это имеет одно очень важное последствие для процесса deploy&amp;rsquo;я:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Мы всегда должны иметь возможность откатиться на предыдущую версию системы, так как пусть редко, но бывает что ошибка все же проходит сквозь все рубежи тестирования и попадает на production. Причем rollback должен осуществлятся не медленнее чем rollout.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Это приводит нас к следующему заключению: &lt;em&gt;следующая версия системы всегда должна быть обратно-совместима с предыдущей&lt;/em&gt;. Это касается не только кода, но и схемы БД, данных в кеше и т.д.&lt;/p&gt;

&lt;p&gt;Оказывается, что когда новая версия системы обратно совместима с текущей, нет ничего страшного в том чтобы некоторое время они поработали вместе.&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;На практике&lt;/h2&gt;
&lt;p&gt;Итак, как это все происходит на практике. Разработчик заходит через &lt;code&gt;ssh&lt;/code&gt; на машину-координатор, куда автоматически доставляются артефакты приложений. У каждого приложения есть отдельная директория содержимое которой выглядит примерно следующим образом:&lt;/p&gt;

&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;-rw-rw-r-- 1 tech tech      101 Jun 24 16:42 .config
-rw-rw-r-- 1 tech tech     1134 Jun  9 13:05 config.properties
-rw-r--r-- 1 tech tech      163 May 16 16:11 .jettyrc
-rw-r--r-- 1 tech tech 30298960 Jun  3 19:41 search-web-frontend-1.0.118.war
-rw-r--r-- 1 tech tech 30299011 Jun  3 21:25 search-web-frontend-1.0.119.war
-rw-r--r-- 1 tech tech 30298949 Jun 13 21:51 search-web-frontend-1.0.120.war
-rw-r--r-- 1 tech tech 30297647 Jun 14 12:38 search-web-frontend-1.0.121.war
-rw-r--r-- 1 tech tech 30297689 Jun 15 11:50 search-web-frontend-1.0.122.war
-rw-r--r-- 1 tech tech 30298356 Jun 15 12:13 search-web-frontend-1.0.123.war
-rw-r--r-- 1 tech tech 30298678 Jun 15 12:32 search-web-frontend-1.0.124.war
-rw-r--r-- 1 tech tech 30732203 Jun 23 11:45 search-web-frontend-1.0.125.war
-rw-r--r-- 1 tech tech 30732204 Jun 23 11:55 search-web-frontend-1.0.126.war
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Здесь есть несколько файлов о которых стоит рассказать поподробнее. Файл &lt;code&gt;.config&lt;/code&gt; это обыкновенный &lt;code&gt;ini&lt;/code&gt;-файл хранящий имена всех машин на которых установлено приложение, а также некоторые другие настройки развертывания. &lt;code&gt;config.properties&lt;/code&gt; — это &lt;code&gt;properties&lt;/code&gt;-файл, который содержит настройки приложения. &lt;code&gt;.jettyrc&lt;/code&gt; содержит startup опции виртуальной машины на которой стартует Jetty.&lt;/p&gt;

&lt;p&gt;За довольно длительное время мы перепробовали различные способы работы с конфигурационными файлами приложений. Мы хранили их в development системе контроля версий. Мы создавали для них отдельный репозиторий в зоне production. Текущая схема нам нравится больше всего. Она позволяет автоматически бекапить все конфигурационные файлы приложений, что безусловно необходимо, а также не связываться с излишей сложностью VCS систем для управления &amp;ldquo;двумя файлами из 10 строчек каждый&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;Если запустить команду deploy без аргументов, то она выведет текущее состояние нодов:&lt;/p&gt;

&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;$ deploy 
http://search-service1:8080 - Ok com.farpost.search:search-web-frontend 1.0.126
http://search-service2:8080 - Ok com.farpost.search:search-web-frontend 1.0.126
http://search-service3:8080 - Ok com.farpost.search:search-web-frontend 1.0.126
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Благодаря &lt;a href=&quot;http://maven.apache.org/&quot;&gt;maven&lt;/a&gt; во все наши сборки автоматически попадает информация о версии, а также номере билда.&lt;/p&gt;

&lt;p&gt;Если же передать команде deploy имя артефакта, то начнется его развертывание на production машинах.&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;Дальнейшие соображения&lt;/h2&gt;
&lt;p&gt;Текущий процесс нас вполне устраивает, тем не менее у нас есть идеи как сделать его еще лучше.&lt;/p&gt;

&lt;h3 id=&quot;runtime---&quot;&gt;Runtime обновление конфигурации логгирования&lt;/h3&gt;
&lt;p&gt;Мы используем &lt;a href=&quot;http://logback.qos.ch/&quot;&gt;logback&lt;/a&gt; в качестве библиотеки логгирования. Существенным ее плюсом является то что она позволяет &lt;a href=&quot;http://logback.qos.ch/manual/configuration.html#autoScan&quot;&gt;менять конфигурацию логгирования на лету&lt;/a&gt;. Достаточно просто поменять XML файл с конфигурацией. Было бы неплохо иметь возможность распространять конфигурацию логгирования на машины без перезагрузки самого приложения.&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;Дифференцирование конфигурации различных нодов&lt;/h3&gt;
&lt;p&gt;В распределенной системе разные ноды могут иметь идентичную сборку, но разную конфигурацию, обуславливающую требуемую разность в их поведении. Сейчас у нас пока что нет возможности задать разную конфигурацию для разных нодов. Учитывая что конфигурация задается в виде &lt;code&gt;properties&lt;/code&gt; файлов, сделать такого рода дифференциорание не сложно.&lt;/p&gt;

&lt;h3 id=&quot;partial-deploy&quot;&gt;Partial deploy&lt;/h3&gt;
&lt;p&gt;Иногда бывает необходимо обновить не весь кластер, а только один нод из кластера. В будущем, я думаю мы сделаем такую возможность.&lt;/p&gt;

&lt;p&gt;Вот пожалуй и все. А как деплоите приложения вы? ;)&lt;/p&gt;

</description>
    </item>
    
    <item>
      <title>Fair lock</title>
      <link>http://bazhenov.me/blog/2011/04/17/fair-lock.html</link>
      <pubDate>Sun, 17 Apr 2011 00:00:00 +1100</pubDate>
      <author>dotsid@gmail.com (Denis Bazhenov)</author>
      <guid>http://bazhenov.me/blog/2011/04/17/fair-lock</guid>
      <description>&lt;p&gt;Не так давно у нас на собеседовании был кандидат, который произвел довольно хорошее впечатление, поэтому было решено предложить ему более сложную задачу, которую обычно мы не спрашиваем. Вот ее немного видоизмененный вариант.&lt;/p&gt;

&lt;!-- excerpt --&gt;

&lt;blockquote&gt;
  &lt;p&gt;Переделайте следующий код оставив его многопоточным таким образом, чтобы лампочки зажигались и гасли строго по очереди и в любой момент времени должна быть включена только одна лампочка:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre class=&quot;code&quot;&gt;&lt;code&gt;package me.bazhenov.bulb;

public class Main {

	public static void main(String[] args) {
		new Thread(new Bulb(&quot;first&quot;)).start();
		new Thread(new Bulb(&quot;seconds&quot;)).start();
	}
}

public class Bulb implements Runnable {

	private final String name;

	public Bulb(String name) {
		this.name = name;
	}

	public void run() {
		Thread self = currentThread();
		while(!self.isInterrupted()) {
			System.out.println(name + &quot; bulb is on&quot;);
			try {
				sleep(300);
			} catch (InterruptedException e) {
				self.interrupt();
			}
			System.out.println(name + &quot; bulb is off&quot;);
		}
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Кандидат предложил использовать &lt;a href=&quot;http://download.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/locks/ReentrantLock.html&quot;&gt;&lt;code&gt;ReentrantLock&lt;/code&gt;&lt;/a&gt; в &lt;code&gt;FairSync&lt;/code&gt; режиме. В первом приближении эта идея может показаться рабочей. Передать общий лок в оба оъекта типа Bulb и синхронизироватся там на нем. Тем не менее, этот подход не работает. Если мы заглянем в документацию к классу, то увидим следующее описание:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The constructor for this class accepts an optional fairness parameter. When set true, under contention, locks favor granting access to the longest-waiting thread. Otherwise this lock does not guarantee any particular access order. [&amp;hellip;] Note however, that fairness of locks does not guarantee fairness of thread scheduling.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code&gt;FairSync&lt;/code&gt; не гарантирует отсутствие race condition&amp;rsquo;а между потоками. Единственное что он гарантирует это то, что лок возьмет поток который ждал на локе дольше всего. Отсутствие контроля за CPU шедулером не дает нам гарантии что в момент когда поток отпускает лок его оппонент уже попытался сделать acquire на этом же локе (что необходимо для того чтобы сработал FairSync в этой задаче).&lt;/p&gt;

&lt;p&gt;К сожалению у меня нет под рукой соответствующего железа, но я подозреваю что на однопроцессорной машине разницы между FairSync и NonfairSync вообще не будет, так как у параллельного потока не будет возможности поставить в очередь заявку на acquire, чтобы при следующем unlock&amp;rsquo;е его заявка была обслужена.&lt;/p&gt;

&lt;p&gt;Правильное же решение задачи остается на совести читателя :)&lt;/p&gt;

</description>
    </item>
    
    <item>
      <title>Маленький Билд и его друзья</title>
      <link>http://bazhenov.me/blog/2011/04/09/build.html</link>
      <pubDate>Sat, 09 Apr 2011 00:00:00 +1100</pubDate>
      <author>dotsid@gmail.com (Denis Bazhenov)</author>
      <guid>http://bazhenov.me/blog/2011/04/09/build</guid>
      <description>&lt;p&gt;Помните фильм &amp;ldquo;Пятый элемент&amp;rdquo;? Там была сцена, когда Зорг опрокидывает стакан на пол и роботы тут же начинают уборку помещения. Всего лишь одно маленькое действие привело в жизнь десяток машин, которые сразу же начали подметать и мыть полы, а в конце еще и налили воды хозяину.&lt;/p&gt;

&lt;p&gt;Что-то похожее происходит в коллективе с налаженным build процессом, когда разработчик коммитит изменения в систему контроля версий.&lt;/p&gt;

&lt;p&gt;О пользе налаженного процесса билда известно много. Но &amp;ldquo;путь на production&amp;rdquo; не прост. После того как код написан и перед тем как он будет запущен на production&amp;rsquo;е было бы неплохо сделать следующие вещи:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;откомпилировать код если вы используете компилируемый язык (удивил, да?);&lt;/li&gt;
  &lt;li&gt;прогнать модульные и интеграционные тесты если они у вас есть;&lt;/li&gt;
  &lt;li&gt;выполнить статический анализ кода и/или другие проверки которые позволяет выполнить ваша платформа и которые имеют смысл для вашей команды (code style check, code coverage, цикломатическая сложность, dependency matrix и т.д.);&lt;/li&gt;
  &lt;li&gt;собрать артефакт приложения (желательно в виде одного файла), содержащий в себе весь код и ресурсы необходимые для запуска приложения на целевой платформе;&lt;/li&gt;
  &lt;li&gt;выполнить приемочное тестирование, если оно у вас есть;&lt;/li&gt;
  &lt;li&gt;опубликовать артефакт в репозитории (предположительно локальном), чтобы другие члены комманды могли им воспользоватся в своих целях (особенно актуально, если вы разрабатываете билиотеку, а не приложение);&lt;/li&gt;
  &lt;li&gt;в случае если вы разрабатываете приложение а не библиотеку, произвести deploy в окружение staging тестирования чтобы команда и менеджеры могли оценить текущее состояние проекта.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Этот список действий не догма и варьируется от потребностей проекта. Я же расскажу что и как делаем мы. Сразу отмечу что у нас в проекте используется две платформы: PHP и Java. Я преимущественно буду описывать как мы собираем Java проекты, так как за счет поддержки инструментария билд процесс там получается более целостный и вразумительный. Я думаю, этот опыт будет полезен читателям.&lt;/p&gt;

&lt;p&gt;Итак код закоммичен в систему контроля версий. С этого момента начинается его маленькое путешествие на production. Но для начала давайте познакомимся с главными героями. Для того чтобы успешно проводить автоматизированною сборку проекта необходим определенный инструментарий.&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;В главных ролях&lt;/h2&gt;

&lt;h3 id=&quot;vcs&quot;&gt;Система контроля версий (VCS)&lt;/h3&gt;

&lt;p&gt;Какую VCS систему использовать решать вам. Это может быть старый проверенный временем &lt;a href=&quot;http://subversion.apache.org/&quot;&gt;subversion&lt;/a&gt;, или модно-распределенный &lt;a href=&quot;http://git-scm.com/&quot;&gt;git&lt;/a&gt;/&lt;a href=&quot;http://mercurial.selenic.com/&quot;&gt;mercurial&lt;/a&gt;. Но она должна быть. Если на вашем календаре уже 2011 год и вы все еще не пользуетесь какой-либо системой контроля версий, то я настоятельно советую вам переоценить принципы согласно котрым вы принимаете решения.&lt;/p&gt;

&lt;p&gt;В контексте обсуждения процесса сборки выбор системы контроля версий настолько неважен, что я даже не буду говорить какую используем мы :)&lt;/p&gt;

&lt;h3 id=&quot;build-tool&quot;&gt;Система сборки проектов (build tool)&lt;/h3&gt;

&lt;p&gt;Основная задача системы сборки состоит в автоматизации задач связанных с созданием релиза из исходных кодов. Среди программистов работающих с интепретируемыми языками распространено мнение что исходный код и есть релиз. Связано это судя по всему с тем, что в таких языках нет выделенной фазы компиляции. Я считаю, что даже в этом случае разделение между исходниками и релизами нужно, потому что вне зависимости от того на каком языке программирования написано приложение, релиз должен обладать следующими свойствами, которыми не обладают исходные коды:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;любой релиз в отличии от исходных кодов должен работать. Подтверждатся это должно каким-либо видом тестирования (хотя бы ручным). Исходные коды же могут находится некоторое время в нерабочем состоянии (например, во время рефакторинга);&lt;/li&gt;
  &lt;li&gt;релиз может содержать third party библиотеки и программное обеспечение, которое разрабатывается и поддерживается третьими лицами. Хранить все это в системе контроля версий может быть не самым удобным решением;&lt;/li&gt;
  &lt;li&gt;платформа на которой работает приложение может иметь ограничения на формат релиза. Например, может быть строго определен формат архива с приложением (например, rpm или deb). Хранить исходные коды в VCS в том же формате может быть очень неудобно c точки зрения разработки.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Выражаясь математически: релиз = ƒ(исходники).&lt;/p&gt;

&lt;p&gt;Для сборки мы используем &lt;a href=&quot;http://maven.apache.org/&quot;&gt;Apache Maven&lt;/a&gt;, &amp;ndash; это довольно зрелая и продвинутая система сборки, которая впрочем не так проста в изучении как ее более &amp;ldquo;легковесные&amp;rdquo; братья вроде &lt;a href=&quot;http://ant.apache.org/&quot;&gt;ant&lt;/a&gt; и &lt;a href=&quot;http://gradle.org/&quot;&gt;gradle&lt;/a&gt; (хотя ant — это скорее бабушка, а gradle внучатый племянник). Gradle в последнее время получил довольно много положительных отзывов и продолжает набирать популярность, поэтому вам определенно стоит посмотреть на него, если вы определяетесь с вопросом выбора системы сборки Java-проекта.&lt;/p&gt;

&lt;p&gt;Для того чтобы использовать maven более эффективно, у нас есть определенная экосистема для его поддержки.&lt;/p&gt;

&lt;p&gt;Во-первых, это репозиторий артефактов о котором я расскажу ниже.&lt;/p&gt;

&lt;p&gt;Во-вторых, у нас есть общийэ POM-дескриптор для всех проектов компании, который определяет настройки компилятора, сразу делает доступными библиотеки повсеместно используемые в нашей компании (TestNG, hamcrest, logback и т.д.), а также настраивает плагины для статического анализа кода и логгирования и т.д.&lt;/p&gt;

&lt;p&gt;В третьих, у нас есть несколько прототипов проектов (&lt;a href=&quot;http://maven.apache.org/guides/introduction/introduction-to-archetypes.html&quot;&gt;archetype&lt;/a&gt; в терминологии maven), которые позволяют одной командой из консоли создать новый проект. Эдакий hello world с уже настроенным логированием, &lt;a href=&quot;http://docs.codehaus.org/display/JETTY/Maven+Jetty+Plugin&quot;&gt;Jetty для тестирования&lt;/a&gt;, &lt;a href=&quot;http://activemq.apache.org/&quot;&gt;ActiveMQ&lt;/a&gt; и &lt;a href=&quot;http://www.springsource.org/spring-integration&quot;&gt;Spring Integration&lt;/a&gt; для обработки сообщений, &lt;a href=&quot;http://www.springsource.org/&quot;&gt;Spring&lt;/a&gt; в качестве web-framework&amp;rsquo;а и много еще чем. Все это очень сильно упрощает старт, особенно людям не знакомым с премудростями настройки всего этого &amp;ldquo;зоопарка&amp;rdquo;.&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;Репозиторий артефактов&lt;/h3&gt;

&lt;p&gt;Еще один вопрос связанный с системой билда — куда ложить его результат? После того как мы собрали приложение и протестировали его, нам надо опубликовать релиз. Необходимо общее централизованное место где бы хранились все артефакты, чтобы любой разработчик знал где искать последний релиз продукта. Позже вы можете достать его и использовать для deploy&amp;rsquo;я на production или в окружение staging тестирования. Если вы разрабатываете библиотеку то релиз нужен другим членам команды, для того чтобы использовать ее в своем приложении.&lt;/p&gt;

&lt;p&gt;В простейшем случае роль репозитория может играть web-сервер. Его настройка для этих задач не займет у вас много времени. Либо это может быть FTP-сервер или сетевой диск доступный всем разработчикам. Так же эту роль может играть continious integration сервер, речь о котором пойдет ниже.&lt;/p&gt;

&lt;p&gt;В более сложных случаях удачным решением может быть специализирванное ПО. Особенно это актуально если вы используете Maven, который специфицирует формат репозиториев и протокол работы с ними (поверх HTTP).&lt;/p&gt;

&lt;p&gt;Мы используем &lt;a href=&quot;http://www.jfrog.com/products.php&quot;&gt;Artifactory&lt;/a&gt; в качестве репозитория, который выполняет несколько ролей в нашей экосистеме:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;хранит артефакты делая их (и их исходники) доступными для использования любым программистом в любое время;&lt;/li&gt;
  &lt;li&gt;кеширует third party библиотеки используемые программистами. Если вы начинаете новый проект и хотите использовать какую-то библиотеку, с высокой долей вероятности она уже есть в локальном репозитории и вы получите ее моментально не дожидаясь загрузки из интернета.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;continuous-integration-&quot;&gt;Continuous Integration сервер&lt;/h3&gt;

&lt;p&gt;Не смотря на грозное название, CI-сервера по своей сути — это триггеры билд процесса которые предоставляют разработчикам удобный способ контроллировать процесс и результат сборок. Они делают несколько вещей:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;позволяют конфигурировать политику запуска сборки (при коммите в VCS, через заданные интевалы времени, после успешной сборки зависимого проекта, вручную, и т.д.);&lt;/li&gt;
  &lt;li&gt;предоставляют возможность следить за процессом сборки публикуя ее логи через web-интерфейс;&lt;/li&gt;
  &lt;li&gt;предоставляют отчеты по результатам билда (проваленные тесты, предупреждения статического анализатора и т.д.);&lt;/li&gt;
  &lt;li&gt;строят тренды на основании истории сборок (количество тестов, время затраченное на исправление билда, процент успешных сборок и т.д.);&lt;/li&gt;
  &lt;li&gt;могут успешно играть роль репозитория артефактов.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Строго говоря использование CI-сервера не обязательно. Более того, на начальных этапах я бы рекомендовал делать сборки на машинах разработчиков. Это позволит сэкономить вам время в процессе допиливания build-процесса, которое на начальных стадиях неизбежно.&lt;/p&gt;

&lt;p&gt;Мы до сих пор не используем CI-сервер для сборки билиотек. Библиотеки собираются и релизятся самим программистами. Несмотря на то что этот подход имеет ряд недостатков, он существенно проще.&lt;/p&gt;

&lt;p&gt;В качестве CI-сервера мы используем &lt;a href=&quot;http://www.jetbrains.com/teamcity/&quot;&gt;TeamCity&lt;/a&gt;, бесплатной версией которой мы полностью довольны. Одна из привлекательных фич этого продукта состоит в том что он предоставляет неплохую статистику по билдам, включая success rate сборок, количество тестов и т.д.&lt;/p&gt;

&lt;p class=&quot;image photo&quot;&gt;&lt;img src=&quot;/images/build/fig1.png&quot; alt=&quot;TeamCity&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;Поезд отправляется&lt;/h2&gt;

&lt;p&gt;Итак как это все происходит на практике.&lt;/p&gt;

&lt;p&gt;За системой контроля версий следит continuous integration сервер. Как только он замечает какие либо изменения, он делает checkout свежей версии и инициирует процесс сборки проекта.&lt;/p&gt;

&lt;p&gt;TeamCity позволяет очень детально настроить с какими параметрами будет запущен build. Вы можете предопределить значения системных переменных нужных вашему процессу билда. Эти переменные могут использоваться например для того чтобы специфицировать на какой БД будет выполнятся тестирование.&lt;/p&gt;

&lt;p class=&quot;image photo&quot;&gt;&lt;img src=&quot;/images/build/fig2.png&quot; alt=&quot;TeamCity: Custom Build&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Затем в работу вступает Maven. Он компилирует исходники, запускает модульные тесты. Если они провалились, то генерирует отчеты по проваленным тестам, которые будут затем показаны на персональной странице билда, а сам билд завершается и считается проваленным:&lt;/p&gt;

&lt;p class=&quot;image photo&quot;&gt;&lt;img src=&quot;/images/build/fig3.png&quot; alt=&quot;Failed Build&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Если тесты проходят, то &amp;ldquo;состав движется дальше&amp;rdquo;. Следующим шагом является сборка артефактов. В терминах continious integration &lt;em&gt;артефакт&lt;/em&gt; это любой результат процесса сборки, главная черта которого — воспроизводимость. Для нас это означает что артефакт является процессом работы машины, а не ручных действий человека.&lt;/p&gt;

&lt;p&gt;Обратите внимание, что в смежных областях знаний, например в configuration management, термин &amp;ldquo;артефакт&amp;rdquo; имеет немного отличные значения.&lt;/p&gt;

&lt;p&gt;Воспроизводимость артефакта — очень важное его свойство. Оно позволяет в любой момент времени из любого среза VCS попытатся собрать приложение и посмотреть что из этого получится.&lt;/p&gt;

&lt;p&gt;Воспроизводимость артефакта служит хорошей поддержкой для так популярных в наше время итеративных методов разработки, смысл которых состоит в идее &amp;ldquo;&lt;em&gt;давайте начнем стрелять, а потом будем корректировать огонь&lt;/em&gt;&amp;rdquo;. Когда патроны дешевле чем время, это хороший подход. Налаженный процесс автоматического производства артефактов в этом контексте можно сравнить с автоматическим станком по производству патронов. Чем лучше он у вас отточен, тем дешевле ваши патроны, и тем быстрее вы можете стрелять и получать фидбек критически важный для следующей итерации.&lt;/p&gt;

&lt;p&gt;После того как артефакт собран Maven принимается за интеграционное и приемочное тестирование. Здесь необходимо отметить зачем разделение между модульными, интеграционными и приемочными тестами.&lt;/p&gt;

&lt;p&gt;Модульные тесты тестируют классы в изоляции от других частей системы, а также в изоляции от внешних систем, таких как базы данных и веб-сервисы. Их задача состоит в том чтобы давать программисту быстрый фидбек относительно того, работает система или нет безотносительно того верно ли она интегрируется с внешними источниками данных. Фактически, любой программист должен иметь возможность сделать checkout исходников проекта, запустить модульные тесты на абсолютно не подготовленной машине (например, без базы данных) и тесты должны выполнится. Единственная причина почему они могут не выполнится, это если в коде приложения допущена ошибка.&lt;/p&gt;

&lt;p&gt;Таким образом, у модульных тестов не должно быть зависимостей, отличных от тех которые тест может удовлетворить сам. По личному опыту могу сказать: тех кто не соблюдаете это правило ждет не очень приятное будущее.&lt;/p&gt;

&lt;p&gt;В сухом остатке. Модульные тесты должны:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;выполнятся быстро. Потолок 15-20 секунд, затем их просто перестают использовать. Здесь нужно обратить внимание на то, что модульные тесты должны выполнятся именно на стороне программиста и как можно чаще. И конечно же обязательно перед коммитом в систему контроля версий. На CI-сервере они выполнятся лишь для полноты тестирования;&lt;/li&gt;
  &lt;li&gt;быть изолированными от внешнего окружения и выполнятся даже на машине без сети.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;В отличии от модульных, интеграционные тесты проверяют как приложение дружит с внешними системами, и как следствие, обладают следующим рядом особенностей:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;могут требовать довольно сложное окружение для своего выполнения (конкретную БД, возможно даже конкретной версии);&lt;/li&gt;
  &lt;li&gt;могут быть довольно медленными, так как включают в себя взаимодействие по сети, зачастую с системами производительность которых находятся под контролем третьих лиц;&lt;/li&gt;
  &lt;li&gt;являются гораздо более хрупкими чем модульные, потому что опираются на заранее установленное окружение, а также на программное обеспечение которое скорее всего меняется без оглядки на ваше конкретное приложение.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Тем не менее тестировать все равно надо, поэтому такие тесты выделяются в отдульную группу и запускаются на CI-сервере. Настроить и поддерживать в актуальном состоянии сложное окружение проще один раз на сервере, чем десять раз на машинах разработчиков. Разработчик может запустить интеграционные тесты у себя, но для этого он должен настроить хотя бы часть окружения на своей машине, что может быть довольно непросто. Частично эти проблему можно решить при помощи виртуализации и таких инструментов как &lt;a href=&quot;http://www.puppetlabs.com/&quot;&gt;puppet&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Обычно интеграционные тесты на стороне разработчика запускаются только в случае если менялся интеграционный код системы и как правило только тесты на изменившуюся часть системы. С точки зрения maven (а именно, &lt;a href=&quot;http://maven.apache.org/plugins/maven-surefire-plugin/&quot;&gt;maven-surefire-plugin&lt;/a&gt;) интеграционные тесты отличаются от модульных только постфиксом (&lt;code&gt;*Test&lt;/code&gt; у модульных, &lt;code&gt;*IT&lt;/code&gt; у интеграционных). После того как тесту задан соответствующий постфикс, он автоматически начинает запускатся на нужной фазе сборки проекта.&lt;/p&gt;

&lt;p&gt;Если с интеграционными тестами все хорошо, то запускаются приемочные. Приемочные тесты проверяют систему по типу черного ящика. Если вы разрабатываете web-приложение, то оно запускается на web-сервере и тест под видом обыкновенного пользователя начинает ходить по нему и проверять его работоспособность. Пожалуй, это один из самых сложных видов тестирования. В нем довольно легко наделать ошибок, которые могут существенно увеличить стоимость поддержки тестовой инфраструктуры. Это в конце концов делает процесс тестирования менее эффективным. Впрочем, тема приемочного тестирования выходит далеко за рамки моего поста, поэтому я не буду заострять на этом сейчас внимание. Людям искушенным очень советую прочитать книгу Джеза Хамбла и Девида Ферли &lt;a href=&quot;http://continuousdelivery.com/&quot;&gt;Continuous Delivery&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Ну а мы отправляемся дальше. Следуюшая остановка — статический анализ кода. Мы используем &lt;a href=&quot;http://mojo.codehaus.org/findbugs-maven-plugin/&quot;&gt;findbugs&lt;/a&gt; для анализа кода. Статические анализаторы действительно находят ошибки и потенциальные уязвимости, так почему бы не делать это при каждом изменении наших исходных файлов.&lt;/p&gt;

&lt;p class=&quot;image photo&quot;&gt;&lt;img src=&quot;/images/build/fig4.png&quot; alt=&quot;Code Analysis&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Можно указать TeamCity чтобы при превышении опредленного порога по количеству найденных проблемных ситуаций, билд считался проваленным.&lt;/p&gt;

&lt;p&gt;Но, данный шаг можно порекомендовать не всем. Во-первых, для этого требуется существенная поддержка инструментов. Например, для php нет ничего подобного. Во-вторых, получаемая от статического анализатора информация должна оцениваться прагматически. Помните что анализатор показывает риски с формальной точки зрения. У каждого риска есть &lt;em&gt;вероятность материализации&lt;/em&gt; и &lt;em&gt;стоимость исправления&lt;/em&gt;. Вероятность материализации — это вероятность с которой риск превратится в проблему (то есть вы сможете наблюдать его воочию). Стоимость исправления — это сколько ресурсов (например, в виде человеко часов) нам надо будет потратить если риск все же материализуется в проблему. Перемножив эти два числа мы получим &lt;em&gt;математическое ожидание проблемы&lt;/em&gt;. Может оказаться так, что математическое ожидание проблемы гораздо меньше чем стоимость внесения изменений в код здесь и сейчас. Некоторые проблемы дешевле исправлять пост фактум.&lt;/p&gt;

&lt;p&gt;После того как статический анализ кода законечен, закончен и процесс непосредственно сборки. Теперь нам осталось опубликовать артефакт в общедоступный репозиторий и можно рапортовать об успешности билда.&lt;/p&gt;

&lt;p&gt;Деплой у нас происходит в два этапа. Первый этап это деплой в локальный репозиторий артефактов. Второй этап включает в себя автоматическую доставку приложения на production сервера. Обратите внимание, &lt;em&gt;доставку&lt;/em&gt;, но не &lt;em&gt;deploy&lt;/em&gt;. Deploy осуществляется только по инициативе и под контролем разработчика. Таким образом, если разаботчик работает над проектом &lt;code&gt;search-service&lt;/code&gt; версии 1.0 и на TeamCity успешно выполнился билд под номером 134, то на production кластере в папке проекта автоматически появляется файл &lt;code&gt;search-service-1.0.134.war&lt;/code&gt;, который содержит в себе все необходимое для работы приложения и готов к развертыванию по команде разработчика. Это позволяет свести к минимуму участие человека в процессе билда. Человек привлекается только там где его внимание и возможность принимать решения не может заменить машина.&lt;/p&gt;

&lt;p&gt;Вот пожалуй и все. Некоторые моменты остались за кадром. Например, как происходит запуск (deploy) приложения на production серверах. Но это тема совсем другого разговора.&lt;/p&gt;

&lt;p&gt;Буду рад услышать отзывы и success stories читателей.&lt;/p&gt;

</description>
    </item>
    
  </channel> 
</rss>