<?xml version="1.0"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Суровая реальность</title>
    <link>http://bazhenov.me</link>
    <atom:link href="http://bazhenov.me/rss.xml" rel="self" type="application/rss+xml" />
    <description>Суровая реальность</description>
    <language>ru-ru</language>
    <pubDate>Mon, 23 Jul 2012 21:46:56 +1100</pubDate>
    <lastBuildDate>Mon, 23 Jul 2012 21:46:56 +1100</lastBuildDate>
    
    <item>
      <title>Оценка классификатора (точность, полнота, F-мера)</title>
      <link>http://bazhenov.me/blog/2012/07/21/classification-performance-evaluation.html</link>
      <pubDate>Sat, 21 Jul 2012 00:00:00 +1100</pubDate>
      <author>Denis Bazhenov (dotsid@gmail.com)</author>
      <guid isPermaLink="true">http://bazhenov.me/blog/2012/07/21/classification-performance-evaluation.html</guid>
      <description>&lt;p&gt;Продолжая тему реализации &lt;a href=&quot;http://bazhenov.me/blog/2012/06/11/naive-bayes.html&quot;&gt;автоматической классификации&lt;/a&gt; необходимо обсудить следующий очень важный вопрос. Как оценивать качество алгоритма? Допустим, вы хотите внести изменения в алгоритм. Откуда вы знаете что эти изменения сделают алгоритм лучше? Конечно же надо проверять алгоритм на реальных данных.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;h2 id=&quot;section&quot;&gt;Тестовая выборка&lt;/h2&gt;

&lt;p&gt;Основой проверки является тестовая выборка в которой проставлено соответствие между документами и их классами. В зависимости от ваших конкретных условий получение подобной выборки может быть затруднено, так как зачастую ее составляют люди. Но иногда ее можно получить без большого объема ручной работы, если проявить изобретательность. Каких-то конеретных рецептов, к сожалению, не существует.&lt;/p&gt;

&lt;p&gt;Когда у вас появилась тестовая выборка достаточно натравить классификатор на документы и соотнести его решение с заведомо известным правильным решением. Но для того чтобы принимать решение хуже или лучше справляется с работой новая версия алгоритма &lt;em&gt;нам необходима численная метрика его качества&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;Численная оценка качества алгоритма&lt;/h2&gt;

&lt;h3 id=&quot;accuracy&quot;&gt;Accuracy&lt;/h3&gt;

&lt;p&gt;В простейшем случае такой метрикой может быть доля документов по которым классификатор принял правильное решение.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Accuracy = \frac{P}{N}&lt;/script&gt;

&lt;p&gt;где, &lt;script type=&quot;math/tex&quot;&gt;P&lt;/script&gt; – количество документов по которым классификатор принял правильное решение, а &lt;script type=&quot;math/tex&quot;&gt;N&lt;/script&gt; – размер обучающей выборки. Очевидное решение, на котором для начала можно остановиться.&lt;/p&gt;

&lt;p&gt;Тем не менее, у этой метрики есть одна особенность которую необходимо учитывать. Она присваивает всем документам одинаковый вес, что может быть не корректно в случае если распределение документов в обучающей выборке сильно смещено в сторону какого-то одного или нескольких классов. В этом случае у классификатора есть больше информации по этим классам и соответственно в рамках этих классов он будет принимать более адекватные решения. На практике это приводит к тому, что вы имеете accuracy, скажем, 80%, но при этом в рамках какого-то конкретного класса классификатор работает из рук вон плохо не определяя правильно даже треть документов.&lt;/p&gt;

&lt;p&gt;Один выход из этой ситуации заключается в том чтобы обучать классификатор на специально подготовленном, сбалансированном корпусе документов. Минус этого решения в том что вы отбираете у классификатора информацию об отностельной частоте документов. Эта информация при прочих равных может оказаться очень кстати для принятия правильного решения.&lt;/p&gt;

&lt;p&gt;Другой выход заключается в изменении подхода к формальной оценке качества.&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;Точность и полнота&lt;/h3&gt;

&lt;p&gt;Точность (precision) и полнота (recall) являются метриками которые используются при оценке большей части алгоритмов извлечения информации. Иногда они используются сами по себе, иногда в качестве базиса для производных метрик, таких как F-мера или R-Precision. Суть точности и полноты очень проста.&lt;/p&gt;

&lt;p&gt;Точность системы в пределах класса – это доля документов действительно принадлежащих данному классу относительно всех документов которые система отнесла к этому классу. Полнота системы – это доля найденных классфикатором документов принадлежащих классу относительно всех документов этого класса в тестовой выборке.&lt;/p&gt;

&lt;p&gt;Эти значения легко рассчитать на основании таблицы контингентности, которая составляется для каждого класса отдельно.&lt;/p&gt;

&lt;p class=&quot;image&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/classification-performance-evaluation/contingency-table.png&quot; alt=&quot;Таблица контингентности&quot; /&gt;&lt;/p&gt;

&lt;p&gt;В таблице содержится информация сколько раз система приняла верное и сколько раз неверное решение по документам заданного класса. А именно:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;TP&lt;/script&gt; — истино-положительное решение;&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;TN&lt;/script&gt; — истино-отрицательное решение;&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;FP&lt;/script&gt; — ложно-положительное решение;&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;FN&lt;/script&gt; — ложно-отрицательное решение.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Тогда, точность и полнота определяются следующим образом:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt; Precision = \frac{TP}{TP+FP} &lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt; Recall = \frac{TP}{TP+FN} &lt;/script&gt;

&lt;blockquote&gt;
  &lt;p&gt;Рассмотрим пример. Допустим, у вас есть тестовая выборка в которой 10 сообщений, из них 4 – спам. Обработав все сообщения классификатор пометил 2 сообщения как спам, причем одно действительно является спамом, а второе было помечено в тестовой выборке как нормальное. Мы имеем одно истино-положительное решение, три ложно-отрицательных и одно ложно-положительное. Тогда для класса &amp;ldquo;спам&amp;rdquo; точность классификатора составляет &lt;script type=&quot;math/tex&quot;&gt;\frac{1}{2}&lt;/script&gt; (50% положительных решений правильные), а полнота &lt;script type=&quot;math/tex&quot;&gt;\frac{1}{4}&lt;/script&gt; (классификатор нашел 25% всех спам-сообщений).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;confusion-matrix&quot;&gt;Confusion Matrix&lt;/h2&gt;

&lt;p&gt;На практике значения точности и полноты гораздо более удобней рассчитывать с использованием матрицы неточностей (confusion matrix). В случае если количество классов относительно невелико (не более 100-150 классов), этот подход позволяет довольно наглядно представить результаты работы классификатора.&lt;/p&gt;

&lt;p&gt;Матрица неточностей – это матрица размера N на N, где N — это количество классов. Столбцы этой матрицы резервируются за экспертными решениями, а строки за решениями классификатора. Когда мы классифицируем документ из тестовой выборки мы инкрементируем число стоящее на пересечении строки класса который вернул классификатор и столбца класса к которому действительно относится документ.&lt;/p&gt;

&lt;p class=&quot;image&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/classification-performance-evaluation/confusion-matrix.png&quot; alt=&quot;Матрица неточностей&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;description&quot;&gt;Матрица неточностей (26 классов, результирующая точность – 0.8, результирующая полнота – 0.91)&lt;/p&gt;

&lt;p&gt;Как видно из примера, большинство документов классификатор определяет верно. Диагональные элементы матрицы явно выражены. Тем не менее в рамках некоторых классов (3, 5, 8, 22) классификатор показывает низкую точность.&lt;/p&gt;

&lt;p&gt;Имея такую матрицу точность и полнота для каждого класса рассчитывается очень просто. Точность равняется отношению соответствующего диагонального элемента матрицы и суммы всей строки класса. Полнота – отношению диагонального элемента матрицы и суммы всего столбца класса. Формально:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Precision_c = \frac{A_{c,c}}{\sum_{i=1}^n A_{c,i}}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Recall_c = \frac{A_{c,c}}{\sum_{i=1}^n A_{i,c}}&lt;/script&gt;

&lt;p&gt;Результирующая точность классификатора рассчитывается как арифметическое среднее его точности по всем классам. То же самое с полнотой. Технически этот подход называется macro-averaging.&lt;/p&gt;

&lt;h2 id=&quot;f-&quot;&gt;F-мера&lt;/h2&gt;

&lt;p&gt;Понятно что чем выше точность и полнота, тем лучше. Но в реальной жизни максимальная точность и полнота не достижимы одновременно и приходится искать некий баланс. Поэтому, хотелось бы иметь некую метрику которая объединяла бы в себе информацию о точности и полноте нашего алгоритма. В этом случае нам будет проще принимать решение о том какую реализацию запускать в production (у кого больше тот и круче). Именно такой метрикой является F-мера&lt;sup id=&quot;fnref:f-measure&quot;&gt;&lt;a href=&quot;#fn:f-measure&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;F-мера представляет собой &lt;a href=&quot;http://bazhenov.me/blog/2012/05/05/harmonic-mean.html&quot;&gt;гармоническое среднее&lt;/a&gt; между точностью и полнотой. Она стремится к нулю, если точность или полнота стремится к нулю.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;F = 2 \frac{Precision \times Recall}{Precision + Recall}&lt;/script&gt;

&lt;p&gt;Данная формула придает одинаковый вес точности и полноте, поэтому F-мера будет падать одинаково при уменьшении и точности и полноты. Возможно рассчитать F-меру придав различный вес точности и полноте, если вы осознанно отдаете приоритет одной из этих метрик при разработке алгоритма.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;F = \left(\beta^2+1\right)\frac{Precision \times Recall}{\beta^2 Precision + Recall}&lt;/script&gt;

&lt;p&gt;где &lt;script type=&quot;math/tex&quot;&gt;\beta&lt;/script&gt; принимает значения в диапазоне &lt;script type=&quot;math/tex&quot;&gt;0&lt;\beta&lt;1&lt;/script&gt; если вы хотите отдать приоритет точности, а при &lt;script type=&quot;math/tex&quot;&gt;\beta &gt; 1&lt;/script&gt; приоритет отдается полноте. При &lt;script type=&quot;math/tex&quot;&gt;\beta = 1&lt;/script&gt; формула сводится к предыдущей и вы получаете сбалансированную F-меру (также ее называют F&lt;sub&gt;1&lt;/sub&gt;).&lt;/p&gt;

&lt;p class=&quot;image&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/classification-performance-evaluation/F-1.png&quot; alt=&quot;Сбалансированная F-мера&quot; /&gt;&lt;/p&gt;
&lt;p class=&quot;description&quot;&gt;Сбалансированная F-мера&lt;/p&gt;

&lt;p class=&quot;image&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/classification-performance-evaluation/F-1-over-4.png&quot; alt=&quot;F-мера с приоритетом точности&quot; /&gt;&lt;/p&gt;
&lt;p class=&quot;description&quot;&gt;F-мера с приоритетом точности (&lt;script type=&quot;math/tex&quot;&gt;\beta^2 = \frac{1}{4}&lt;/script&gt;)&lt;/p&gt;

&lt;p class=&quot;image&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/classification-performance-evaluation/F-2.png&quot; alt=&quot;F-мера с приоритетом полноты&quot; /&gt;&lt;/p&gt;
&lt;p class=&quot;description&quot;&gt;F-мера с приоритетом полноты (&lt;script type=&quot;math/tex&quot;&gt;\beta^2 = 2&lt;/script&gt;)&lt;/p&gt;

&lt;p&gt;F-мера является хорошим кандидатом на формальную метрику оценки качества классификатора. Она сводит к одному числу две других основополагающих метрики: точность и полноту. Имея в своем распоряжении подобный механизм оценки вам будет гораздо проще принять решение о том являются ли изменения в алгоритме в лучшую сторону или нет.&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;Ссылки по теме&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;http://datamin.ubbcluj.ro/wiki/index.php/Evaluation_methods_in_text_categorization&quot;&gt;Evaluation methods in text categorization&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://rushdishams.blogspot.com/2011/08/micro-and-macro-average-of-precision.html&quot;&gt;Micro and macro average of precision&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://ru.wikipedia.org/wiki/Информационный_поиск#.D0.9E.D1.86.D0.B5.D0.BD.D0.BA.D0.B8_.D1.8D.D1.84.D1.84.D0.B5.D0.BA.D1.82.D0.B8.D0.B2.D0.BD.D0.BE.D1.81.D1.82.D0.B8&quot;&gt;Информационный поиск: Оценка эффективности — Wikipedia&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Precision_and_recall&quot;&gt;Precision and Recall — Wikipedia&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://cmp.felk.cvut.cz/~hlavac/TeachPresEn/31PattRecog/13ClassifierPerformance.pdf&quot;&gt;Classifier performance evaluation&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:f-measure&quot;&gt;
      &lt;p&gt;иногда встречаются названия: F-score или мера Ван Ризбергена.&lt;a href=&quot;#fnref:f-measure&quot; rel=&quot;reference&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Самый наивный классификатор</title>
      <link>http://bazhenov.me/blog/2012/06/11/naive-bayes.html</link>
      <pubDate>Mon, 11 Jun 2012 00:00:00 +1100</pubDate>
      <author>Denis Bazhenov (dotsid@gmail.com)</author>
      <guid isPermaLink="true">http://bazhenov.me/blog/2012/06/11/naive-bayes.html</guid>
      <description>&lt;p&gt;В &lt;a href=&quot;http://bazhenov.me/blog/2012/06/05/classification.html&quot;&gt;прошлой заметке&lt;/a&gt; я в общих чертах описал задачу классификации, а также традиционные подходы используемые для классификации текстовых документов. В этой заметке я более детально расскажу о том как работает самый простой, но вместе с тем один из самых часто используемых при обработке натуральных языков алгоритм классификации – &lt;a href=&quot;http://ru.wikipedia.org/wiki/Наивный_байесовский_классификатор&quot;&gt;наивный байесовский классификатор&lt;/a&gt;.&lt;/p&gt;

&lt;!-- excerpt --&gt;

&lt;p&gt;Заметка разбита на две части: &lt;a href=&quot;#theory&quot;&gt;теоретическая&lt;/a&gt;, в которой описаны аспекты классификации, и &lt;a href=&quot;#practice&quot;&gt;практическая&lt;/a&gt; часть построения классификатора. Если вы хотите быстро создать прототип классификатора, то обратитесь к практической части заметки, там на приводится пример классификатора. Также на github доступны &lt;a href=&quot;https://github.com/bazhenov/naive-bayes-example&quot;&gt;исходники примера&lt;/a&gt;. Если же вам интересны теоретические принципы работы классификации, то обратитесь к теоретической части заметки.&lt;/p&gt;

&lt;h2 id=&quot;theory&quot;&gt;Теория&lt;/h2&gt;

&lt;p&gt;Осторожно, в этой части заметки много формул.&lt;/p&gt;

&lt;p&gt;В основе NBC (Naïve Bayes Classifier) лежит, как вы уже могли догадаться, &lt;a href=&quot;http://ru.wikipedia.org/wiki/Теорема_Байеса&quot;&gt;теорема Байеса&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;$$ P(c|d) = \frac{ P(d|c)P(c) }{ P(d) } $$&lt;/p&gt;

&lt;p&gt;где,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$ P(c|d) $ — вероятность что документ $d$ принадлежит классу $c$, именно её нам надо рассчитать;&lt;/li&gt;
  &lt;li&gt;$ P(d|c) $ — вероятность встретить документ $d$ среди всех документов класса $c$;&lt;/li&gt;
  &lt;li&gt;$ P(c) $ — безусловная вероятность встретить документ класса $c$ в корпусе документов;&lt;/li&gt;
  &lt;li&gt;$ P(d) $ — безусловная вероятность документа $d$ в корпусе документов.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Её смысл на обывательском уровне можно выразить следующим образом. Теорема Байеса позволяет переставить местами причину и следствие. Зная с какой вероятностью причина приводит к некоему событию, эта теорема позволяет расчитать вероятность того что именно эта причина привела к наблюдаемому событию.&lt;/p&gt;

&lt;p&gt;Цель классификации состоит в том чтобы понять к какому классу принадлежит документ, поэтому нам нужна не сама вероятность, а наиболее вероятный класс. Байесовский классификатор использует &lt;a href=&quot;http://ru.wikipedia.org/wiki/Оценка_апостериорного_максимума&quot;&gt;оценку апостериорного максимума&lt;/a&gt; (Maximum a posteriori estimation) для определения наиболее вероятного класса. Грубо говоря, это класс с максимальной вероятностью.&lt;/p&gt;

&lt;p&gt;$$ c_{map}=\operatorname*{arg\,max}_{c \in C} \frac{ P(d|c)P(c) }{ P(d) }$$&lt;/p&gt;

&lt;p&gt;То есть нам надо рассчитать вероятность для всех классов и выбрать тот класс, который обладает максимальной вероятностью. Обратите внимание, знаменатель (вероятность документа) является константой и никак не может повлиять на ранжирование классов, поэтому в нашей задаче мы можем его игнорировать.&lt;/p&gt;

&lt;p&gt;$$ c_{map}=\operatorname*{arg\,max}_{c \in C} \left[ P(d|c)P(c) \right] $$ &lt;/p&gt;

&lt;p class=&quot;description&quot;&gt;Формула №1&lt;/p&gt;

&lt;p&gt;Далее делается допущение которое и объясняет почему этот алгоритм называют наивным.&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;Предположение условной независимости&lt;/h3&gt;

&lt;p&gt;Если я вам скажу &amp;ldquo;темно как у негра в &amp;hellip;&amp;rdquo;, вы сразу поймете о каком месте чем идет речь, даже если я не закончу фразу. Так происходит потому что &lt;em&gt;в натуральном языке вероятность появления слова сильно зависит от контекста&lt;/em&gt;. Байесовский же классификатор представляет документ как набор слов вероятности которых условно не зависят друг от друга. Этот подход иногда еще называется &lt;a href=&quot;http://en.wikipedia.org/wiki/Bag_of_words_model&quot;&gt;bag of words model&lt;/a&gt;. Исходя из этого предположения условная вероятность документа аппроксимируется произведением условных вероятностей всех слов входящих в документ.&lt;/p&gt;

&lt;p&gt;$$ P(d|c) \approx P(w_1|c)P(w_2|c)&amp;hellip;P(w_n|c) = \prod_{i=1}^n P(w_i|c) $$&lt;/p&gt;

&lt;p&gt;Этот подход также называется Unigram Language Model. Языковые модели играют очень важную роль в задачах обработки натуральных языков, но выходят за пределы этой заметки.&lt;/p&gt;

&lt;p&gt;Подставив полученное выражение в формулу №1 мы получим:&lt;/p&gt;

&lt;p&gt;$$ c_{map}=\operatorname*{arg\,max}_{c \in C} \left[ P(c) \prod_{i=1}^n P(w_i|c) \right] $$&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;Проблема арифметического переполнения&lt;/h3&gt;

&lt;p&gt;При достаточно большой длине документа придется перемножать большое количество очень маленьких чисел. Для того чтобы при этом избежать &lt;a href=&quot;http://en.wikipedia.org/wiki/Arithmetic_underflow&quot;&gt;арифметического переполнения снизу&lt;/a&gt; зачастую пользуются свойством логарифма произведения $\log ab = \log a+\log b$. Так как логарифм функция монотонная, ее применение к обоим частям выражения изменит только его численное значение, но не параметры при которых достигается максимум. При этом, логарифм от числа близкого к нулю будет числом отрицательным, но в абсолютном значении существенно большим чем исходное число, что делает логарифмические значения вероятностей более удобными для анализа. Поэтому, мы переписываем нашу формулу с использованием логарифма.&lt;/p&gt;

&lt;p&gt;$$ c_{map}=\operatorname*{arg\,max}_{c \in C} \left[ \log P(c)+\sum_{i=1}^n \log P(w_i|c) \right] $$&lt;/p&gt;

&lt;p class=&quot;description&quot;&gt;Формула №2&lt;/p&gt;

&lt;p&gt;Основание логарифма в данном случае не имеет значения. Вы можете использовать как натуральный, так и любой другой логарифм.&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;Оценка параметров Байесовской модели&lt;/h3&gt;

&lt;p&gt;Оценка вероятностей $ P(c) $ и $ P(w_i|c) $ осуществляется на обучающей выборке. Вероятность класса мы можем оценить как:&lt;/p&gt;

&lt;p&gt;$$ P(c)=\frac{D_c}{D} $$&lt;/p&gt;

&lt;p&gt;где, $D_c$ – количество документов принадлежащих классу $c$, а $D$ – общее количество документов в обучающей выборке.&lt;/p&gt;

&lt;p&gt;Оценка вероятности слова в классе может делаться несколькими путями. Здесь я приведу multinomial bayes model.&lt;/p&gt;

&lt;p&gt;$$ P(w_i|c)=\frac{W_{ic}}{ \sum_{i&amp;rsquo;\in V} W_{i&amp;rsquo;c} } $$&lt;/p&gt;

&lt;p class=&quot;description&quot;&gt;Формула №3&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$W_{ic}$ — количество раз сколько $i$-ое слово встречается в документах класса $c$;&lt;/li&gt;
  &lt;li&gt;$V$ — словарь корпуса документов (список всех уникальных слов).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Другими словами, числитель описывает сколько раз слово встречается в документах класса (включая повторы), а знаменатель – это суммарное количество слов во всех документах этого класса.&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;Проблема неизвестных слов&lt;/h3&gt;

&lt;p&gt;С формулой №3 есть одна небольшая проблема. Если на этапе классификации вам встретится слово которого вы не видели на этапе обучения, то значения $W_{ic}$, а следственно и $P(w_i|c)$ будут равны нулю. &lt;em&gt;Это приведет к тому что документ с этим словом нельзя будет классифицировать, так как он будет иметь нулевую вероятность по всем классам&lt;/em&gt;. Избавиться от этой проблемы путем анализа б&lt;strong&gt;о&lt;/strong&gt;льшего количества документов не получится. Вы никогда не сможете составить обучающую выборку содержащую все возможные слова включая неологизмы, опечатки, синонимы и т.д. Типичным решением проблемы неизвестных слов является &lt;a href=&quot;http://en.wikipedia.org/wiki/Additive_smoothing&quot;&gt;аддитивное сглаживание&lt;/a&gt; (сглаживание Лапласа). Идея заключается в том что мы притворяемся как будто видели каждое слово на один раз больше, то есть прибавляем единицу к частоте каждого слова.&lt;/p&gt;

&lt;p&gt;$$ P(w_i|c)=\frac{W_{ic}+1}{ \sum_{i&amp;rsquo;\in V} \left( W_{i&amp;rsquo;c} + 1 \right) } = \frac{W_{ic}+1}{ |V| + \sum_{i&amp;rsquo;\in V} W_{i&amp;rsquo;c} } $$&lt;/p&gt;

&lt;p&gt;Логически данный подход смещает оценку вероятностей в сторону менее вероятных исходов. Таким образом, слова которые мы не видели на этапе обучения модели получают пусть маленькую, но все же не нулевую вероятность. Вот как это выглядит на практике. Допустим на этапе обучения мы видели три имени собственных указанное количество раз.&lt;/p&gt;

&lt;table class=&quot;center&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Имя&lt;/th&gt;
      &lt;th&gt;Частота&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Вася&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Петя&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Женя&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;И тут на этапе классификации у нас появляется имя Иннокентий, которое мы не видели на этапе обучения. Тогда оригинальная и смещённая по Лапласу оценка вероятностей будет выглядеть следующим образом.&lt;/p&gt;

&lt;p class=&quot;image&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/naive-bayes/additive-smoothing.png&quot; alt=&quot;Смещёная и несмещённая оценка вероятности&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Из графика видно что смещённая оценка никогда не бывает нулевой, что защищает нас от проблемы неизвестных слов.&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;Собираем все вместе&lt;/h3&gt;

&lt;p&gt;Подставив выбранные нами оценки в формулу №2 мы получаем окончательную формулу по которой происходит байесовская классификация.&lt;/p&gt;

&lt;p&gt;$$ c_{map}=\operatorname*{arg\,max}_{c \in C} \left[ \log\frac{D_c}{D} + \sum_{i=1}^n\log{\frac{W_{ic}+1}{ |V|+\sum_{i&amp;rsquo;\in V} W_{i&amp;rsquo;c}}} \right] $$&lt;/p&gt;

&lt;p class=&quot;description&quot;&gt;Формула №4&lt;/p&gt;

&lt;h2 id=&quot;practice&quot;&gt;Реализация классификатора&lt;/h2&gt;

&lt;p&gt;Для реализации Байесовского классификатора нам необходима обучающая выборка в которой проставлены соответствия между текстовыми документами и их классами. Затем нам необходимо собрать следующую статистику из выборки, которая будет использоваться на этапе классификации:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;относительные частоты классов в корпусе документов. То есть, как часто встречаются документы того или иного класса;&lt;/li&gt;
  &lt;li&gt;суммарное количество слов в документах каждого класса;&lt;/li&gt;
  &lt;li&gt;относительные частоты слов в пределах каждого класса;&lt;/li&gt;
  &lt;li&gt;размер словаря выборки. Количество уникальных слов в выборке.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Совокупность этой информации мы будем называть моделью классификатора. Затем на этапе классификации необходимо для каждого класса рассчитать значение следующего выражения и выбрать класс с максимальным значением.&lt;/p&gt;

&lt;p&gt;$$ \log\frac{D_c}{D} + \sum_{i \in Q}\log{\frac{W_{ic}+1}{ |V|+L_{c} }} $$&lt;/p&gt;

&lt;p class=&quot;description&quot;&gt;Упрощенная запись формулы №4&lt;/p&gt;

&lt;p&gt;в этой формуле:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$D_c$ — количество документов в обучающей выборке принадлежащих классу $c$;&lt;/li&gt;
  &lt;li&gt;$D$ — общее количество документов в обучающей выборке;&lt;/li&gt;
  &lt;li&gt;$|V|$ — количество уникальных слов во всех документах обучающей выборки;&lt;/li&gt;
  &lt;li&gt;$L_{c}$ — суммарное количество слов в документах класса $c$ в обучающей выборке;&lt;/li&gt;
  &lt;li&gt;$W_{ic}$ — сколько раз $i$-ое слово встречалось в документах класса $c$ в обучающей выборке;&lt;/li&gt;
  &lt;li&gt;$Q$ – множество слов классифицируемого документа (включая повторы).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Информация необходимая для осознания смысла этого выражения приведена выше в разделе &lt;a href=&quot;#theory&quot;&gt;Теория&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;section-5&quot;&gt;Пример&lt;/h3&gt;

&lt;p&gt;Допустим, у нас есть три документа для которых известны их классы (HAM означает – не спам):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;[SPAM]&lt;/code&gt; предоставляю услуги бухгалтера;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;[SPAM]&lt;/code&gt; спешите купить виагру;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;[HAM]&lt;/code&gt; надо купить молоко.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Модель классификатора будет выглядеть следующим образом:&lt;/p&gt;

&lt;table class=&quot;center&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&amp;nbsp;&lt;/th&gt;
      &lt;th&gt;spam&lt;/th&gt;
      &lt;th&gt;ham&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;частоты классов&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;суммарное количество слов&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table class=&quot;center&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&amp;nbsp;&lt;/th&gt;
      &lt;th&gt;spam&lt;/th&gt;
      &lt;th&gt;ham&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;предоставляю&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;услуги&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;бухгалтера&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;спешите&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;купить&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;виагру&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;надо&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;молоко&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Теперь классифицируем фразу &amp;ldquo;надо купить сигареты&amp;rdquo;. Рассчитаем значение выражения для класса SPAM:&lt;/p&gt;

&lt;p&gt;$$ \log\frac{2}{3} + \log\frac{1}{8+6} + \log\frac{2}{8+6} + \log\frac{1}{8+6} \approx -7.629 $$&lt;/p&gt;

&lt;p&gt;Теперь сделаем то же самое для класса HAM:&lt;/p&gt;

&lt;p&gt;$$ \log\frac{1}{3} + \log\frac{2}{8+3} + \log\frac{1}{8+3} + \log\frac{1}{8+3} \approx -6.906 $$&lt;/p&gt;

&lt;p&gt;В данном случае класс HAM выиграл и сообщение не будет помечено как спам.&lt;/p&gt;

&lt;h2 id=&quot;section-6&quot;&gt;В заключении&lt;/h2&gt;

&lt;h3 id=&quot;show-me-the-code&quot;&gt;Show me the code&lt;/h3&gt;

&lt;p&gt;На github &lt;a href=&quot;https://github.com/bazhenov/naive-bayes-example&quot;&gt;доступен пример&lt;/a&gt; описанного классификатора реализованный на Scala. Имплементация занимает 50 с лишним строк кода, разобраться с ним у вас не составит труда, просто посмотрите тест &lt;code&gt;ClassifierSpec&lt;/code&gt;. Для запуска тестов необходим &lt;a href=&quot;http://maven.apache.org/&quot;&gt;Maven&lt;/a&gt;.&lt;/p&gt;

&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;$ mvn test
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;section-7&quot;&gt;Вопросы оставшиеся за бортом&lt;/h3&gt;

&lt;p&gt;Сушествует целый ряд вопросов который остался без рассмотрения на текущий момент:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;как тестировать качество алгоритмов классификации;&lt;/li&gt;
  &lt;li&gt;какими системными проблемами обладает алгоритм наивной байесовской классификации;&lt;/li&gt;
  &lt;li&gt;какие существуют подходы увеличения точности алгоритма.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Учитывая объем данного поста, эти вопросы я смело оставляю для будущих заметок.&lt;/p&gt;

</description>
    </item>
    
    <item>
      <title>О задачах классификации</title>
      <link>http://bazhenov.me/blog/2012/06/05/classification.html</link>
      <pubDate>Tue, 05 Jun 2012 00:00:00 +1100</pubDate>
      <author>Denis Bazhenov (dotsid@gmail.com)</author>
      <guid isPermaLink="true">http://bazhenov.me/blog/2012/06/05/classification.html</guid>
      <description>&lt;p&gt;В этом и следующих постах, я хочу на пальцах описать процесс создания простого классификатора текстовых документов, а также рассказать о некоторых нетипичных с обывательской точки зрения подходах используемых при классификации документов.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://ru.wikipedia.org/wiki/Классификация_документов&quot;&gt;Классификатор&lt;/a&gt; – это алгоритм соотносящий некие входные данные с одним или несколькими классами. В отличие от алгоритмов &lt;a href=&quot;http://ru.wikipedia.org/wiki/Кластерный_анализ&quot;&gt;кластеризации&lt;/a&gt; эти классы должны быть определены заранее. &lt;/p&gt;

&lt;p&gt;Возможно, кому-то это определение покажется слишком общими или академическим, поэтому лучше наверное рассмотреть задачу классификации на примерах. А примеров хоть отбавляй.&lt;/p&gt;

&lt;!-- excerpt --&gt;

&lt;h2 id=&quot;section&quot;&gt;Они повсюду&lt;/h2&gt;

&lt;p&gt;Пожалуй самый яркий пример автоматической классификации – это фильтрация спама. Каждый день на мой ящик падает десятки если не сотни спам-писем, которые автоматически отфильтровываются из моего inbox&amp;rsquo;а.&lt;/p&gt;

&lt;p class=&quot;image photo&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/classification/spam.png&quot; alt=&quot;Mail Spam&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Современные коммерческие системы способны успешно фильтровать спам с точностью превышающей 99%&lt;sup id=&quot;fnref:google-spam-filter-performance&quot;&gt;&lt;a href=&quot;#fn:google-spam-filter-performance&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. Другим довольно типичным примером классификации служит автоматическое определение тематики того или иного текста. Некоторые новостные аггрераторы используют подобный подход для группировки новостей в направления: экономика, политика, общественная жизнь и т.д.&lt;/p&gt;

&lt;p&gt;Зачастую классификация является фундаментом на котором строятся алгоритмы решения более сложных задач.
Например, классификация используется при создании рекомендательных систем и в частности при реализации &lt;a href=&quot;http://ru.wikipedia.org/wiki/Коллаборативная_фильтрация&quot;&gt;коллаборативной фильтрации&lt;/a&gt;.&lt;/p&gt;

&lt;p class=&quot;image photo&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/classification/recommendation.png&quot; alt=&quot;Amazon recommendations&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Safari Reader Mode является еще одним примером где используются алгоритмы классификации для достижения конечной цели. Суть этого режима работы браузера заключается в том что он позволяет автоматически убрать со страницы всю шелуху не имеющую отношения к сути контента страницы&lt;sup id=&quot;fnref:boilerplate-paper&quot;&gt;&lt;a href=&quot;#fn:boilerplate-paper&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p class=&quot;image photo&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/classification/reader-mode.png&quot; alt=&quot;Safari Reader Mode&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Так же классификация используется в задачах face detection&amp;rsquo;а и face recognition&amp;rsquo;а.&lt;/p&gt;

&lt;p class=&quot;image photo&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/classification/face-detection.png&quot; alt=&quot;Face Detection in Aperture&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Классификация используется как инструмент для решения множества других задач:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;снятие омонимии при обработке натуральных языков;&lt;/li&gt;
  &lt;li&gt;в поисковых системах – для ограничения области поиска в целях повышения точности (вертикальный поиск);&lt;/li&gt;
  &lt;li&gt;автоматическое определение языка на котором написан текст;&lt;/li&gt;
  &lt;li&gt;анализ тональности (определение эмоциональной окраски текста).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Этот список можно продолжать еще долго. Например, в медицине алгоритмы классификации используются для реконструирования 3D модели головного мозга по серии МРТ снимков&lt;sup id=&quot;fnref:mri-3d&quot;&gt;&lt;a href=&quot;#fn:mri-3d&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;, а также для диагностики пациентов страдающих синдромом Альцгеймера&lt;sup id=&quot;fnref:alzheimer&quot;&gt;&lt;a href=&quot;#fn:alzheimer&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;Традиционные подходы&lt;/h2&gt;

&lt;h3 id=&quot;rule-based-classification&quot;&gt;Rule based classification&lt;/h3&gt;

&lt;p&gt;Если говорить о задаче классификации текстов, то пожалуй ее традиционным решением является классификация основная на правилах (rule based classification). Вы имплементируете правила определения класса документа по его тексту в виде &lt;code&gt;if-then-else&lt;/code&gt; выражений (код на Scala).&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;&lt;code&gt;def classify(text: String) =
	if (text.contains(&quot;виагра&quot;) || text.contains(&quot;бухгалтер&quot;)) &quot;SPAM&quot; else &quot;NOT SPAM&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Этот подход может быть хорошим вариантом если вы работаете с небольшой коллекцией документов которую вы способны охватить и тщательно проанализировать. Просто потому что вы четко контролируете правила по которым классификатор принимает решения. Но есть у этого подхода и очевидные минусы:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;для того чтобы выбрать значимые для классификации слова необходимо обладать экспертными знаниями в предметной области. Есть ли у вас например соображения по поводу ключевых слов которые хорошо отличают документы посвященные финансовой тематике от документов экономической? У меня очень смутные;&lt;/li&gt;
  &lt;li&gt;отнюдь не всегда факт наличия или отсутствия какого-либо одного слова является решающим фактором для принятия решения.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Поподробней остановлюсь на последнем пункте. Если вернуться к задаче определения спама и немного подумать о том какие слова являются хорошими классификационными признаками (classifying feature), то станет понятно что нет такого слова наличие которого гарантировало бы что сообщение является спамом. Возможно, в пределах компании производящей &lt;a href=&quot;http://ru.wikipedia.org/wiki/Силденафил&quot;&gt;силденафил&lt;/a&gt; в промышленных масштабах слово &amp;ldquo;виагра&amp;rdquo; не является показательным признаком спам-сообщения, кто знает.&lt;/p&gt;

&lt;p&gt;В общем, суть такова: &lt;em&gt;любое из известных спам-слов пусть редко но встречается в повседневной жизни.&lt;/em&gt; Поэтому, принимать окончательно решение основываясь на факте наличия или отсутствия какого-либо одного слова идея контрпродуктивная. Мы можем усложнять правила добавляя вложенные &lt;code&gt;if&lt;/code&gt;&amp;lsquo;ы. Но довольно быстро вы поймете что возможности человека в формулировании таких правил очень ограничены, потому что &lt;em&gt;сложность правил растет экспоненциально с количеством выбранных для классификации слов&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;weight-based-classification&quot;&gt;Weight based classification&lt;/h3&gt;

&lt;p&gt;Мы можем пойти другим путем. Мы можем для каждого слова выбрать некий вес, который будет означать насколько вероятно что сообщение с этим словом является спамом (0 – никогда не является спамом, 1 – всегда спам).&lt;/p&gt;

&lt;table class=&quot;center&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&amp;nbsp;&lt;/th&gt;
      &lt;th&gt;spam&lt;/th&gt;
      &lt;th&gt;not spam&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;бухгалтер&lt;/td&gt;
      &lt;td&gt;0.99&lt;/td&gt;
      &lt;td&gt;0.01&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;виагра&lt;/td&gt;
      &lt;td&gt;0.99&lt;/td&gt;
      &lt;td&gt;0.01&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;выгодное&lt;/td&gt;
      &lt;td&gt;0.70&lt;/td&gt;
      &lt;td&gt;0.30&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;github&lt;/td&gt;
      &lt;td&gt;0.01&lt;/td&gt;
      &lt;td&gt;0.99&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;В этой таблице перечислены гипотетические веса для четырех слов. Сумма значений в строке должна быть равна единице. Тогда наша классификация может выглядеть следующим образом:&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;&lt;code&gt;def classify(text: String) = {
	val weights = Map(&quot;бухгалтер&quot;-&amp;gt;0.9, &quot;виагра&quot;-&amp;gt;0.99, &quot;выгодное&quot;-&amp;gt;0.7, &quot;github&quot;-&amp;gt;0.01)
	val words = text.split(' ').filter(weights.contains(_))
	val P_spam = words.map(weights(_)).reduce(_ * _)
	val P_not_spam = words.map(1 - weights(_)).reduce(_ * _)
	if (P_spam &amp;gt; P_not_spam) &quot;SPAM&quot; else &quot;NOT SPAM&quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Мы берем каждое слово и определяем суммарный вес документа отдельно для класса &amp;ldquo;спам&amp;rdquo; и класса &amp;ldquo;не спам&amp;rdquo;. Суммарный вес определяется как произведение весов всех известных слов документа. Слова для которых у нас нет веса мы пропускаем при классификации. Какой суммарный вес оказался больше тот класс и побеждает.&lt;/p&gt;

&lt;p&gt;Это более разумный подход, так как он более гибок и принимает решение на основании всех известных слов в тексте. Так же его гораздо проще сопровождать чем полотна &lt;code&gt;if&lt;/code&gt;&amp;lsquo;ов. &lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;Метод машинного обучения&lt;/h2&gt;

&lt;p&gt;А теперь очень важное замечание. &lt;em&gt;Если у нас будет некий способ автоматически подобрать оптимальные веса слов, то данный подход можно считать методом &lt;a href=&quot;http://ru.wikipedia.org/wiki/Машинное_обучение&quot;&gt;машинного обучения&lt;/a&gt;&lt;/em&gt;. Сильно упрощенный, возможно даже гипертрофированный, но по своей сути это именно метод машинного обучения.&lt;/p&gt;

&lt;p&gt;Если быть более точным, то описанный мною метод является зародышем &lt;a href=&quot;http://ru.wikipedia.org/wiki/Наивный_байесовский_классификатор&quot;&gt;наивного байесовского классификатора&lt;/a&gt;. Но не позволяйте названию обмануть вас, NBC (Naïve Bayes Classifier) если не самый, то один из самых часто используемых классификаторов. Тому есть ряд причин:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;он прост в имплементации и тестировании;&lt;/li&gt;
  &lt;li&gt;процесс обучения довольно эффективен по сравнению с другими более сложными классификаторами;&lt;/li&gt;
  &lt;li&gt;на небольших корпусах документов разница между NBC и другими гораздо более сложными алгоритмами классификации зачастую несущественна, а иногда NBC может оказаться и более точным&lt;sup id=&quot;fnref:on-bayes-optimality&quot;&gt;&lt;a href=&quot;#fn:on-bayes-optimality&quot; rel=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;В последующих заметках я более детально опишу вопросы связанные с созданием и тестированием подобного классификатора. Подписывайтесь на &lt;a href=&quot;http://bazhenov.me/rss.xml&quot;&gt;RSS&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;Ссылки по теме&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:google-spam-filter-performance&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://googlesystem.blogspot.com/2007/10/how-gmail-blocks-spam.html&quot;&gt;How Gmail Blocks Spam&lt;/a&gt;&lt;a href=&quot;#fnref:google-spam-filter-performance&quot; rel=&quot;reference&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:boilerplate-paper&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://www.l3s.de/~kohlschuetter/publications/wsdm187-kohlschuetter.pdf&quot;&gt;Boilerplate Detection using Shallow Text Features&lt;/a&gt;&lt;a href=&quot;#fnref:boilerplate-paper&quot; rel=&quot;reference&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:mri-3d&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;amp;arnumber=1352574&amp;amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fiel5%2F9356%2F29717%2F01352574.pdf%3Farnumber%3D1352574&quot;&gt;Automatic classification of MRI images for three-dimensional volume reconstruction by using general regression neural networks&lt;/a&gt;&lt;a href=&quot;#fnref:mri-3d&quot; rel=&quot;reference&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:alzheimer&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://www.ncbi.nlm.nih.gov/pubmed/20542124&quot;&gt;Automatic classification of patients with Alzheimer&amp;rsquo;s disease from structural MRI: a comparison of ten methods using the ADNI database&lt;/a&gt;&lt;a href=&quot;#fnref:alzheimer&quot; rel=&quot;reference&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:on-bayes-optimality&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://www.cc.gatech.edu/fac/Charles.Isbell/classes/reading/papers/bayes-opt.pdf&quot;&gt;On the Optimality of the Simple Bayesian Classifier under Zero-One Loss&lt;/a&gt;&lt;a href=&quot;#fnref:on-bayes-optimality&quot; rel=&quot;reference&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Особенности функциональщины в Java</title>
      <link>http://bazhenov.me/blog/2012/05/12/functional-java.html</link>
      <pubDate>Sat, 12 May 2012 00:00:00 +1100</pubDate>
      <author>Denis Bazhenov (dotsid@gmail.com)</author>
      <guid isPermaLink="true">http://bazhenov.me/blog/2012/05/12/functional-java.html</guid>
      <description>&lt;p&gt;Некоторое время назад мне довелось участвовать в одном из подпроектов целью которого было извлечение упоминаний об автомобилях из произвольного текста с использованием экспертной информации. Это задачу в простонародье называют парсингом :). Так или иначе, этот класс задач имеет свою специфику связанную с относительно большим количеством различных операций над коллекциями. Связано это с необходимостью проверки различных гипотез относительно содержимого анализируемого текста. Оперирование над коллекциями это сильная сторона функциональных языков к которым Java конечно же не относится.&lt;/p&gt;

&lt;!-- excerpt --&gt;

&lt;h2 id=&quot;section&quot;&gt;Императивный подход&lt;/h2&gt;

&lt;p&gt;Классический императивный подход к оперированию коллекциями заключается в написании кода выполняющего обход и обработку каждого элемента коллекции. Типичный map в императивном стиле выглядит следующим образом:&lt;/p&gt;

&lt;pre class=&quot;code java&quot;&gt;&lt;code&gt;List&amp;lt;String&amp;gt; result = new ArrayList&amp;lt;String&amp;gt;();
for (Position p : autocomplete.suggest(q)) {
	result.add(p.getTitle());
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Не так уж и плохо. Но когда подобную операцию надо выполнять несколько раз в пределах одного метода, &lt;code&gt;for&lt;/code&gt;&amp;lsquo;ы начинают мозолить глаз.&lt;/p&gt;

&lt;h2 id=&quot;guava---&quot;&gt;Guava спешит на помощь&lt;/h2&gt;

&lt;p&gt;Мы используем &lt;a href=&quot;http://code.google.com/p/guava-libraries/&quot;&gt;guava&lt;/a&gt; (бывшая google collections) для упрощения оперирования коллекциями. Guava предоставляет массу функциональных примитивов для работы с коллекциями. Несмотря на излишний синтаксический шум, в Java можно применять элементы функционального программирования. Правда не без ограничений. Давайте посмотрим на вышеприведенный пример переписанный с использованием guava.&lt;/p&gt;

&lt;pre class=&quot;code java&quot;&gt;&lt;code&gt;List&amp;lt;String&amp;gt; result = transform(autocomplete.suggest(q), new Function&amp;lt;Position, String&amp;gt;() {
  @Override
  public String apply(final Position input) {
    return input.getTitle();
  }
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Если честно, то стало еще хуже. Если раньше у нас был простой и понятный &lt;code&gt;for&lt;/code&gt;-цикл, то сейчас мешанина из ключевых слов и названий типов. На сегодняшний день это пожалуй самое сильное ограничение Java — &lt;em&gt;объявлять предикаты по месту проблематично из-за синтаксиса анонимных классов&lt;/em&gt;. Поэтому мы пошли на следующее ухищрение.&lt;/p&gt;

&lt;h2 id=&quot;map-&quot;&gt;Вынос предикатов и map-функций&lt;/h2&gt;

&lt;p&gt;Если вы писали в функциональном стиле, то может замечали что существенный процент всех функций передаваемых в &lt;code&gt;filter&lt;/code&gt;/&lt;code&gt;map&lt;/code&gt; являются чистыми функциями (без состояния) и не используют замыкание. Поэтому мы решили вынести их в виде статических членов класса к которым они относятся. Это позволяет определить их один раз в рамках класса к которому они привязаны и использовать в любом месте кодовой базы.&lt;/p&gt;

&lt;p&gt;Например, вышеприведенный пример мы переписываем следующим образом:&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;&lt;code&gt;class Position {

	public static final Function&amp;lt;Position, String&amp;gt; retrieveName = new Function&amp;lt;Position, String&amp;gt;() {
		@Override
		public String apply(final Position input) {
			return input.getTitle();
		}
	};
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Тогда клиент сводится к следующему коду:&lt;/p&gt;

&lt;pre class=&quot;code java&quot;&gt;&lt;code&gt;List&amp;lt;String&amp;gt; result = transform(autocomplete.suggest(q), retrieveName);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;что уже довольно вменяемо. В случае если функция обладает состоянием мы делаем для нее статическую фабрику в классе к которому она относится.&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;&lt;code&gt;class Span {
	
	public static Function&amp;lt;Span, String&amp;gt; chopFromText(final String text) {
		checkNotNull(text);
		return new Function&amp;lt;Span, String&amp;gt;() {
			@Override
			public String apply(Span input) {
				return input.cutFrom(text);
			}
		};
	}
	
	public String cutFrom(String string) {
		return string.substring(start, end);
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;при этом клиент выглядит похожим образом:&lt;/p&gt;

&lt;pre class=&quot;code java&quot;&gt;&lt;code&gt;List&amp;lt;Span&amp;gt; spans = asList(new Span(0, 5), new Span(6, 2), new Span(9, 3));
List&amp;lt;String&amp;gt; words = transform(spans, chopFromText(&quot;Hello to you!&quot;));
// words -&amp;gt; [&quot;Hello&quot;, &quot;to&quot;, &quot;you&quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Этот подход работает благодаря тому что предикаты и map-функции принимают ровно один аргумент по типу которого можно определить к какому классу относить эту функцию. Таким образом, всякий раз когда вам нужен предикат на тип &lt;code&gt;Position&lt;/code&gt; вы знаете что его надо искать именно в классе &lt;code&gt;Position&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;Постскриптум&lt;/h2&gt;

&lt;p&gt;Вы никогда не получите от Java экспрессивности присущей функциональным и тем более динамическим языкам. Поэтому в некотором отношении это конечно полумера. Но сделать свою жизнь немного проще используя элементы функционального программирования все же можно. И я считаю нужно.&lt;/p&gt;

&lt;p&gt;Ну а Java программистам которые незнакомы с guava, я настоятельно советую обратить внимание на эту библиотеку. Она содержит массу вспомогательных классов и статических методов для решения типовых задач возникающий в ежедневной практике. Ее описание с легкостью может занять целый пост, настолько обширен ее функционал.&lt;/p&gt;

</description>
    </item>
    
    <item>
      <title>Гармоническое среднее</title>
      <link>http://bazhenov.me/blog/2012/05/05/harmonic-mean.html</link>
      <pubDate>Sat, 05 May 2012 00:00:00 +1100</pubDate>
      <author>Denis Bazhenov (dotsid@gmail.com)</author>
      <guid isPermaLink="true">http://bazhenov.me/blog/2012/05/05/harmonic-mean.html</guid>
      <description>&lt;p&gt;Сегодня я хочу обсудить следующую проблему. Как мониторить CPU usage на многопроцессорной машине? Конечно же мониторить метрики выдываемые &lt;code&gt;mpstat&lt;/code&gt;. Эта программа выдает процент времени который процессор проводит в различных состояниях (&lt;code&gt;user&lt;/code&gt;, &lt;code&gt;system&lt;/code&gt;, &lt;code&gt;iowait&lt;/code&gt;, &lt;code&gt;idle&lt;/code&gt; и т.д.).&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;$ mpstat 1
Linux 2.6.32-200.13.1.el5uek (search-personal2.vfarm.loc)		05/05/2012 	_x86_64_	(16 CPU)

11:35:52 AM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest   %idle
11:35:53 AM  all    8.34    0.00    0.59    0.06    0.00    0.12    0.00    0.00   90.89
11:35:54 AM  all    7.27    0.00    0.86    0.00    0.00    0.36    0.00    0.00   91.51
11:35:55 AM  all    7.80    0.00    0.45    0.06    0.00    0.17    0.00    0.00   91.53
11:35:56 AM  all    5.33    2.17    0.84    0.00    0.00    0.14    0.00    0.00   91.52
11:35:57 AM  all    5.92    0.00    0.40    0.06    0.00    0.06    0.00    0.00   93.57
11:35:58 AM  all    4.71    0.07    0.42    0.00    0.00    0.14    0.00    0.00   94.67
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;В ретроспективе это выглядит следующим образом:&lt;/p&gt;

&lt;p class=&quot;image photo&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/harmonic-mean/fig1.png&quot; alt=&quot;CPU usage&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Может показаться что у этого сервера нет никаких проблем с CPU. Тем не менее надо учитывать что машина многопроцессорная и может оказаться что нагрузка на ядра не симмитрична. &lt;code&gt;mpstat&lt;/code&gt; же показывает арифметическое среднее, поэтому если вы на 16 процессорной машине видите CPU utilization 6% это может означать:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;машина загружена симметрично и у каждого ядра есть еще масса свободного времени;&lt;/li&gt;
  &lt;li&gt;машина загружена не симметрично – одно ядро работает на 100%, а все остальные курят бамбук.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Конечно же последний случай это явная проблема и система мониторинга должна позволять находить такие ситуации. Но что мониторить чтобы находить ассиметричную нагрузку на различные ядра?&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;Мониторинг&lt;/h2&gt;

&lt;h3 id=&quot;load-average&quot;&gt;Load average&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Load_(computing)&quot;&gt;Load average&lt;/a&gt; (&lt;code&gt;uptime&lt;/code&gt;, &lt;code&gt;w&lt;/code&gt;) не позволяет отследить подобную ассиметричность в нагрузке, так как ее следствием является работа, которая не может быть выполнена параллельно. В этом случае в системе не будет длинной очереди CPU scheduler&amp;rsquo;а, а это именно то что и показывает load average.&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;Мониторить отдельно каждое ядро&lt;/h3&gt;
&lt;p&gt;Можно отслеживать ассиметричность имея информацию по CPU usage для каждого отдельного ядра (на подобии той которая приведена в начале заметки). Но это, как вы можете догадаться довольно напряжно. Слишком много данных, которые надо пропустить через мозг чтобы получить информацию.&lt;/p&gt;

&lt;h3 id=&quot;cpu-utilization&quot;&gt;Экстремальные значения CPU utilization&lt;/h3&gt;
&lt;p&gt;Можно мониторить например максимальное значение CPU utilization. Это позволит понять какая утилизация у самого загруженного ядра в системе. Благодаря этому можно отследить ситуацию ассиметричной нагрузки по разнице между арифметическим средним и максимальным значением утилизации.&lt;/p&gt;

&lt;p&gt;Мы мониторим &lt;a href=&quot;http://en.wikipedia.org/wiki/Harmonic_mean&quot;&gt;гармоническое среднее&lt;/a&gt;. &lt;em&gt;Гармоническое среднее, в отличии арифметического стремится к нулю когда хотя бы одно из значений стремится к нулю.&lt;/em&gt; Считается оно тоже довольно просто — количество значений деленное на сумму обратных значений:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{n}{\sum\limits_{i=1}^n \frac{1}{x_i}}&lt;/script&gt;

&lt;p&gt;То есть для двух процессоров idle которых равен 3 и 100, гармоническое среднее равно: &lt;script type=&quot;math/tex&quot;&gt;\frac{2}{\frac{1}{3} + \frac{1}{100}} \approx 5.8&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Если добавить на график который я привел выше, гармоническое среднее утилизации, то мы получим следующее:&lt;/p&gt;

&lt;p class=&quot;image photo&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/harmonic-mean/fig2.png&quot; alt=&quot;CPU Harmonic Utilization&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Здесь видно что большую часть времени нагрузка распределяется равномерно (светло синей области практически не видно). Тем не менее в период с 1:10 до 1:20 нагрузка на CPU ассиметрична, что говорит о выполнении задачи которая не может быть распараллелена.&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;Что может быть причиной?&lt;/h2&gt;

&lt;p&gt;Это может быть любая активность которая не может быть эффективно распараллелена. Например, банальный &lt;code&gt;grep&lt;/code&gt; по большому объему данных (если он не упрется в I/O), сжатие, потоковое кодирование видео, шифрование, некоторые алгоритмы GC в JVM однопоточные по своей природе.&lt;/p&gt;

&lt;p&gt;Более подробно об этом явлении я уже писал ранее в заметке &amp;ldquo;&lt;a href=&quot;http://bazhenov.me/blog/2009/01/13/moores-law-a-la-finita.html&quot;&gt;Конец эры закона Мура&lt;/a&gt;&amp;rdquo;.&lt;/p&gt;

&lt;p class=&quot;update&quot;&gt;В коментариях мне подсказали что стоит также посмотреть в &lt;code&gt;/proc/interrupts&lt;/code&gt; и в графы &lt;code&gt;%irq&lt;/code&gt; и &lt;code&gt;%soft&lt;/code&gt; вывода &lt;code&gt;mpstat&lt;/code&gt;. На системах с высокой сетевой или дисковой нагрузкой может быть довольно большое число прерываний на одном ядре.&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;Что делать в этой ситуации?&lt;/h2&gt;
&lt;p&gt;Во-первых, надо понять является ли это проблемой. Вполне возможно, что эта ситуация может быть вызвана какой-нибудь background задачей, которая ни коим образом не затрагивает пользователей. Если же данная ситуация влияет на качество сервиса предоставляемого пользователям, то определенно надо более точно локализовать проблему и попытаться разрешить ее.&lt;/p&gt;

&lt;p&gt;На ОС Linux в диагностике подобного рода проблем вам могут помочь следующие инструменты:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;команда &lt;code&gt;pidstat -u -t -p $PID 1&lt;/code&gt; позволяет выяснить какие потоки указанного процесса кушают CPU наиболее активно. Эта команда может быть использована в том числе и для диагностики проблем JVM приложений, так как потоки JVM напрямую соотносятся с потоками ОС;&lt;/li&gt;
  &lt;li&gt;для получения информации по потокам JVM может быть полезна команда &lt;code&gt;jstack $PID&lt;/code&gt;, которая делает thread dump JVM приложения (&lt;code&gt;jstack&lt;/code&gt; является частью JDK и не входит в комплект поставки JRE);&lt;/li&gt;
  &lt;li&gt;для получения трейса конкретного потока можно воспользоваться командами &lt;code&gt;strace&lt;/code&gt;/&lt;code&gt;ltrace&lt;/code&gt;. Они показывают трейс системных вызовов и библиотечных вызовов соответственно.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Надеюсь эти инструменты помогут вам диагностировать подобные ситуации быстро и безболезненно.&lt;/p&gt;

</description>
    </item>
    
  </channel> 
</rss>