<?xml version="1.0"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Суровая реальность</title>
    <link>http://bazhenov.me</link>
    <atom:link href="http://bazhenov.me/rss.xml" rel="self" type="application/rss+xml" />
    <description>Суровая реальность</description>
    <language>ru-ru</language>
    <pubDate>Sun, 14 Apr 2013 23:03:11 +1100</pubDate>
    <lastBuildDate>Sun, 14 Apr 2013 23:03:11 +1100</lastBuildDate>
    
    <item>
      <title>Размер линейного счетчика</title>
      <link>http://bazhenov.me/blog/2013/04/14/linear-counter-bitmask-size.html</link>
      <pubDate>Sun, 14 Apr 2013 00:00:00 +1100</pubDate>
      <author>Denis Bazhenov (dotsid@gmail.com)</author>
      <guid isPermaLink="true">http://bazhenov.me/blog/2013/04/14/linear-counter-bitmask-size.html</guid>
      <description>&lt;p&gt;Для использования &lt;a href=&quot;http://bazhenov.me/blog/2012/12/12/linear-counter.html&quot;&gt;линейного счетчика&lt;/a&gt; необходимо заранее знать приблизительное количество уникальных элементов в потоке. На основании этого количества, а также необходимого вам уровня точности, вычисляется длина битовой маски счетчика.&lt;/p&gt;

&lt;!-- excerpt --&gt;

&lt;p&gt;Допустим, вы хотите создать линейный счетчик для оценки количества элементов в потоке, с максимальным количеством уникальных элементов равным 10 миллионам. Какой длины должна быть битовая маска? Ответ на этот вопрос позволяет найти следующее неравенство:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;m &gt; \max\left(5, \frac{1}{(\epsilon t)^2}\right) \left(e^t - t - 1\right)&lt;/script&gt;

&lt;p&gt;Минимальное положительное целое m, для которого выполняется это неравенство, является длиной маски при которой обеспечивается необходимая точность.&lt;/p&gt;

&lt;p&gt;В этой формуле:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; — длина битовой маски;&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\epsilon&lt;/script&gt; — необходимая точность оценки в виде доли (например, 0.01 для точности 1%);&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; — так называемый, load factor (&lt;script type=&quot;math/tex&quot;&gt;t=\frac{n}{m}&lt;/script&gt;). Отношение количества уникальных элементов в потоке к длине битовой маски.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;К сожалению, у этого неравенства нет алгебраического решения, – из него нельзя выразить m. Для прикладного применения ответ можно получить несколькими способами.&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;Таблицы&lt;/h2&gt;

&lt;p&gt;В &lt;a href=&quot;http://dblab.kaist.ac.kr/Publication/pdf/ACM90_TODS_v15n2.pdf&quot;&gt;оригинальной публикации&lt;/a&gt; приведены таблицы для точности 1 и 10%. Приведу здесь часть таблицы для полноты повествования.&lt;/p&gt;

&lt;table class=&quot;center&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;n&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;1%&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;10%&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;10&lt;sup&gt;2&lt;/sup&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5034&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;80&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;10&lt;sup&gt;3&lt;/sup&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5329&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;268&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;10&lt;sup&gt;4&lt;/sup&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7960&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1709&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;10&lt;sup&gt;5&lt;/sup&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;26729&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;12744&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;10&lt;sup&gt;6&lt;/sup&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;154171&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;100880&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;10&lt;sup&gt;7&lt;/sup&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1096582&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;831809&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Если вам нужна оценка для точности 1 или 10%, её можно узнать путем интерполяцией двух промежуточных значений из таблицы.&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;Определение длины маски численным методом&lt;/h2&gt;

&lt;p&gt;Если табличный метод не подходит, решение можно получить числено. Пожалуй, самый простой и вместе с тем довольно эффективный способ заключается в слегка модифицированном бинарном поиске.&lt;/p&gt;

&lt;p&gt;Использование такого подхода возможно, так как правая часть неравенства хоть и не является дифференцируемой на всём промежутке значений, тем не менее, можно показать, что она монотонно убывает при &lt;script type=&quot;math/tex&quot;&gt;m\to\infty&lt;/script&gt; (так как данная заметка носит прикладной характер, доказательство остается на совести читателя). Это означает, что есть такое вещественное значение &lt;script type=&quot;math/tex&quot;&gt;m_0&lt;/script&gt;, которое делит всю область допустимых значений на две: справа неравенство выполняется, а слева не выполняется. Округлив это значение до ближайшего целого сверху мы получим искомый ответ.&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;&lt;code&gt;int computeRequiredBitMaskLength(double n, double eps) {
	if (eps &amp;gt;= 1 || eps &amp;lt;= 0) {
		throw new IllegalArgumentException(&quot;Epsilon should be in (0, 1) range&quot;);
	}
	if (n &amp;lt;= 0) {
		throw new IllegalArgumentException(&quot;Cardinality should be positive&quot;);
	}
	int fromM = 1;
	int toM = 100000000;
	int m;
	double eq;
	do {
		m = (toM + fromM) / 2;
		eq = precisionInequalityRV(n / m, eps);
		if (m &amp;gt; eq) {
			toM = m;
		} else {
			fromM = m + 1;
		}
	} while (toM &amp;gt; fromM);
	return m &amp;gt; eq ? m : m + 1;
}

double precisionInequalityRV(double t, double eps) {
	return max(1.0 / pow(eps * t, 2), 5) * (exp(t) - t - 1);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Как и любой другой бинарный поиск, этот выполняется за &lt;script type=&quot;math/tex&quot;&gt;O(\log d)&lt;/script&gt; (где d — размер диапазона по которому происходит поиск). Таким образом, этот подход позволяет находить ответ за несколько десятков итераций даже для больших значений d. Этого более чем достаточно для большинства прикладных задач.&lt;/p&gt;

</description>
    </item>
    
    <item>
      <title>Архитектура поисковых систем</title>
      <link>http://bazhenov.me/blog/2013/01/08/search-architecture.html</link>
      <pubDate>Tue, 08 Jan 2013 00:00:00 +1100</pubDate>
      <author>Denis Bazhenov (dotsid@gmail.com)</author>
      <guid isPermaLink="true">http://bazhenov.me/blog/2013/01/08/search-architecture.html</guid>
      <description>&lt;p&gt;Так уж получилось, что последние несколько лет я занимаюсь вопросами, связанными с поиском. Один из проектов, завершенных в прошлом году, был связан с модифицированием архитектуры нашей поисковой системы. В итоге мы получили результаты, которыми, как я считаю, имеет смысл поделиться. So, here we go.&lt;/p&gt;

&lt;!-- excerpt --&gt;

&lt;h2 id=&quot;section&quot;&gt;Функциональность поисковой системы&lt;/h2&gt;
&lt;p&gt;Но для начала было бы неплохо конкретизировать, что именно может и для каких целей используется наша поисковая система.&lt;/p&gt;

&lt;p&gt;На один из наших проектов каждый день заходит более сотни тысяч пользователей в поисках интересующих их товаров и услуг. Именно обслуживание этих запросов является основной задачей поисковой системы, и именно под эту задачу она и проектировалась.&lt;/p&gt;

&lt;p&gt;Под поисковыми запросами в данном случае я понимаю не только запросы на поиск по ключевым словам, но также и атрибутивный поиск (по цене, типу товара и т.д.)&lt;/p&gt;

&lt;p&gt;Наша система способна выполнять следующие типы запросов:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;атрибутивные (на равенство, на вхождение во множество и на вхождение в диапазон для целочисленных значений);&lt;/li&gt;
  &lt;li&gt;полнотекстовые;&lt;/li&gt;
  &lt;li&gt;запросы на построение фасетов.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Типичный запрос к поисковой системе выглядит следующим образом: &amp;ldquo;&lt;code&gt;все автомобили производителя Toyota или Nissan, с типом трансмиссии Автоматическая, во Владивостоке, дешевле 500 000 рублей&lt;/code&gt;&amp;rdquo;. В дополнении к самим документам, удовлетворяющим критериям, поисковая система может вернуть фасеты. Фасет – это список значений указанного поля с указанием количества документов с этим значением поля. Типичные примеры фасетного поиска вы можете увидеть кругом в Интернете.&lt;/p&gt;

&lt;p class=&quot;image photo&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/search-architecture/amazon-facets.png&quot; alt=&quot;Фасеты на примере amazon.com&quot; width=&quot;799&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Также система способна выполнять сортировку (и последующий пейджинг) документов по значению одного из атрибутов или по релевантности.&lt;/p&gt;

&lt;p&gt;Кроме того, система включает в себя более сложный функционал, который относится к информационному поиску: механизмы обработки синонимов, алгоритмы расширения пользовательского запроса для обеспечения полноты и другой функционал, о котором в пределах этой заметки я говорить не буду. Это отдельная тема.&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;Ретроспектива&lt;/h2&gt;

&lt;p&gt;Когда обсуждают архитектуру систем, более важным, чем текущее состояние, на мой взгляд, является ретроспектива развития. Проблемы, которые испытывал проект в прошлом, являются одной из основных движущих сил, определяющих его будущее. Поэтому, я считаю важным рассказать, как поиск работал раньше, и какие проблемы заставили нас сделать то, что мы сделали.&lt;/p&gt;

&lt;p&gt;Поиск работал очень просто. Все документы складывались в отдельную MySQL таблицу, по которой и осуществлялась необходимая фильтрация. Полнотекстовый поиск реализовывался &lt;a href=&quot;http://dev.mysql.com/doc/refman/5.1/en/fulltext-search.html&quot;&gt;встроенными средствами MySQL&lt;/a&gt;. От этого решения мы очень быстро ушли, так как полнотекстовый поиск в MySQL очень ограничен с точки зрения функциональности. Полнотекстовый индекс мы реализовали на &lt;a href=&quot;http://lucene.apache.org/&quot;&gt;Apache Lucene&lt;/a&gt; в виде отдельного сервиса. Во время записи данных в таблицу копия документа отправлялась в этот сервис для индексации текста. При выполнении полнотекстового поиска вычислялось пересечение результатов двух поисков (по MySQL и по Lucene), и результат отдавался клиенту.&lt;/p&gt;

&lt;p&gt;Некоторые инкрементальные изменения в логике хранения были сделаны по ходу эксплуатации. Мы ушли от схемы одна таблица на все предметные области, так как эта таблица получалась очень разряженная (например, у сотовых телефонов нет атрибутов характерных для автомобилей и наоборот), в сторону схемы одна таблица для общих атрибутов + одна таблица на каждую отдельную предметную область. Это позволило немного сэкономить на времени выполнения full scan&amp;rsquo;ов даже не смотря на появившиеся join&amp;rsquo;ы таблиц.&lt;/p&gt;

&lt;p&gt;В этом виде поиск проработал несколько лет. И никто бы его наверное и не трогал, но примерно в тот момент, когда количество актуальных предложений перевалило за миллион, частота возникновения различных проблем заставила нас задуматься о том, что срок жизни этого решения подходит к концу.&lt;/p&gt;

&lt;p&gt;Проблем было несколько:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;intersect join делался путем отправки всех идентификаторов, полученных от Lucene в качестве дополнительного критерия фильтрации в MySQL. Это ставило ограничение на количество документов, которые мы принимаем к фильтрации от полнотекстового индекса, так как у MySQL есть лимит на длину SQL-запроса;&lt;/li&gt;
  &lt;li&gt;так как вариативность условий фильтрации таблицы очень высокая, невозможно было подобрать covered index&amp;rsquo;ы для всех возможных запросов. Фактически, в наших условиях full scan&amp;rsquo;ы были неизбежны. Самым эффективным зачастую оказывался индекс, позволяющий обойти данные в порядке сортировки с фильтрацией не подходящих кортежей на лету. На первый взгляд такой обход кажется крайне не эффективным. Тем не менее, так как все запросы содержат инструкцию &lt;code&gt;LIMIT&lt;/code&gt;, позволяющую БД досрочно прервать выполнение запроса когда будет накоплено достаточное количество предложений, этот подход выигрывал у фильтрации по наиболее подходящему индексу и последующей сортировке;&lt;/li&gt;
  &lt;li&gt;из-за высокой вариативности запросов кеширование принципиально не влияло на latency системы, которое росло линейно с ростом датасета;&lt;/li&gt;
  &lt;li&gt;добавление новых индексов в систему стало очень не тривиальной процедурой из-за необходимости делать блокирующий ALTER TABLE по таблице большого размера.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Таким путем мы пришли к пониманию того, что реляционная БД не может в полной мере удовлетворить наши потребности. И мы начали смотреть по сторонам. Но для начала надо было определится что именно мы хотим получить в итоге.&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;Основные силы, определяющие архитектуру&lt;/h2&gt;

&lt;p&gt;Архитектура определяется потребностями, тем, какой мы хотим видеть систему в будущем, и в каком направлении мы будем ее развивать. Поэтому не лишним будет описать основные факторы, определившие созданное нами решение.&lt;/p&gt;

&lt;h3 id=&quot;transactional--data-&quot;&gt;Возможность transactional и data мастшабирования&lt;/h3&gt;
&lt;p&gt;В момент когда мы формировали облик системы, у нас уже была относительно немаленькая транзакционная нагрузка (несколько сотен поисковых запросов в секунду), и учитывая ретроспективу проекта она должна была расти с известной нам скоростью. Имеющееся у нас на тот момент решение уже было вполне способно масштабироваться по пропускной способности за счет репликации.&lt;/p&gt;

&lt;p&gt;Но было известно также, что существенные ресурсы будут вкладываться в увеличение объема контента, поэтому нам было необходимо решение которое сможет масштабироваться не только по пропускной способности, но и по размеру корпуса документов. Репликация, к сожалению, не является адекватным решением масштабирования по объему данных.&lt;/p&gt;

&lt;p&gt;Также мы хотели получить систему, на операционные проблемы которой (в плане нагрузки) не надо будет отвлекать программистов. Это довольно типичный синдром, нагрузка на систему вырастает, и программистам сразу же приходится бросать свои текущие задачи, чтобы вернуть систему в стабильное состояние. Нам нужна была система, в которой мы могли бы компенсировать нагрузку железом, а не временем разработчиков. Возможность компенсации железом если не решает проблему нагрузки полностью, то позволяет команде не заниматься fire fighting&amp;rsquo;ом. Она дает драгоценное время, чтобы спокойно обдумать сложившуюся ситуацию, после чего без спешки реализовать, протестировать и ввести в эксплуатацию адекватное решение.&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;Отказоустойчивость поиска&lt;/h3&gt;
&lt;p&gt;Оборудование выходит из строя как планово так и внепланово, но люди должны иметь возможность искать интересующие их товары и услуги в любое время дня и ночи вне зависимости от проведения плановых работ или возникновения операционных инцидентов. Естественным ответом на эту потребность является резервирование всех жизненно важных ролей для системы. Если без какого-то звена системы поиск не возможен, это звено должно быть минимум дублировано.&lt;/p&gt;

&lt;p&gt;Требование доступности определило важную архитектурную особенность системы, которая отличает ее от современных open source аналогов, таких как Sphinx, Solr и Elastic Search. Позже я объясню в чем она заключается.&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;Гибкость в реализации сценариев поиска&lt;/h3&gt;
&lt;p&gt;Но самое главное качество поиска заключается не в его скорости, масштабируемости или отказоустойчивости, а в том, что он позволяет пользователям находить интересующие их предложения. Это не так просто как кажется на первый взгляд. Пользователи не всегда точно знают, что они ищут, равно как и не все знают как эффективно пользоваться поиском, чтобы найти нужную информацию. Иногда, они указывают слишком узкие критерии поиска и получают пустую выборку. Это ситуация из которой человеку не просто выбраться. Мы заранее знали, что нам прийдется реализовывать более экзотичные виды поиска.&lt;/p&gt;

&lt;p&gt;Такое положение вещей диктовало дизайну и архитектуре системы еще одно требование. С точки зрения дизайна вся логика, определяющая сценарий поиска, должна соответствовать принципу &lt;a href=&quot;http://en.wikipedia.org/wiki/Open/closed_principle&quot;&gt;OCP&lt;/a&gt;, чтобы ее легко можно было расширять и реализовывать новые сценарии, а архитектурно исполнение кода сценария должно быть отделено от самого индекса, над которым сценарий выполняется.&lt;/p&gt;

&lt;p&gt;Перечисленные выше требования по большей части и сформировали архитектуру всей системы.&lt;/p&gt;

&lt;h3 id=&quot;section-5&quot;&gt;Существующие решения&lt;/h3&gt;
&lt;p&gt;Конечно же в первую очередь мы смотрели на уже существующие open source решения и прикидывали, можем ли мы использовать что-нибудь готовое. Таких решений несколько: &lt;a href=&quot;http://sphinxsearch.com&quot;&gt;Sphinx&lt;/a&gt;, &lt;a href=&quot;http://lucene.apache.org/solr/&quot;&gt;Solr&lt;/a&gt; и &lt;a href=&quot;http://www.elasticsearch.org&quot;&gt;Elastic Search&lt;/a&gt;. В документации у них заявлено, что это distributed и fault-tolerant системы. На практике же и Sphinx и Solr это скорее инструменты для создания такой системы, но сами по себе они таковыми не являются.&lt;/p&gt;

&lt;p&gt;Во-первых, ни одна из вышеперечисленных систем не сохраняет исходные документы. Это означает, что на выходе вы получаете набор идентификаторов, а не документы, которые вы отправляли на индексацию. По этой причине необходимо также обеспечивать и отказоустойчивость базы данных, в которой вы храните первичные данные. В противном случае, поиск вроде как fault-tolerant, но как только БД с первичкой становится недоступна, оказывается что система не в состоянии обслуживать поисковые запросы. По-крайней мере, в том смысле, в котором это понимает пользователь, а именно – показать документы, подпадающие под указанные критерии. Стоит отметить, что физически Solr умеет хранить данные в Lucene-индексе, но сами разработчики настоятельно не рекомендуют этого делать. Связано это в первую очередь с существенными издержками на I/O&lt;sup id=&quot;fnref:ref-solr-stored-performance&quot;&gt;&lt;a href=&quot;#fn:ref-solr-stored-performance&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. &lt;/p&gt;

&lt;p&gt;Во-вторых, ни Sphinx, ни Solr не имплементируют раздельной индексации. То есть подготовки отдельных индексов для различных партиций. Документация по обоим проектам перекладывает эту ответственность на клиента&lt;sup id=&quot;fnref:ref-sphinx-distributed-search&quot;&gt;&lt;a href=&quot;#fn:ref-sphinx-distributed-search&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&quot;fnref:ref-solr-distributed-search&quot;&gt;&lt;a href=&quot;#fn:ref-solr-distributed-search&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;. Насколько мне известно, раздельную индексацию поодерживают только Elastic Search и довольно новый проект &lt;a href=&quot;http://wiki.apache.org/solr/SolrCloud&quot;&gt;SolrCloud&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;И последнее, но не менее важное. На момент принятия решения у нас уже был существенный опыт эксплуатации Apache Lucene. Он у нас использовался в тот момент для обслуживания полнотекстовых запросов. Причем опыт этот был сугубо позитивный. Lucene отлично справлялся с возложенной на него задачей, и довольно быстро появилось осознание того что область его применения гораздо более обширная, чем просто fulltext поиск.&lt;/p&gt;

&lt;p&gt;В итоге мы решили реализовать собственный интеграционный слой поверх Apache Lucene и &lt;a href=&quot;http://www.oracle.com/technetwork/products/berkeleydb/overview/index-093405.html&quot;&gt;Berkeley DB JE&lt;/a&gt; в качестве БД для документов, который бы предоставил все требуемые нам возможности.&lt;/p&gt;

&lt;p&gt;На Berkeley DB выбор пал по нескольким причинам. Предполагаемые паттерны доступа были очень простые (только по первичному ключу), поэтому мы сразу начали оценивать целесообразность применения NoSQL решения для хранения документов. Упрощенная модель данных, если подходит под задачу, при прочих равных дает целый ряд преимуществ: меньше сюрпризов с производительностью, простая диагностика проблем, относительно дешевая отказоустойчивость. Berkeley DB хорошо подошел под наши сценарии использования. Это CP система, у нее мигрирующий мастер и запись по кворуму, что позволяет и читать, и писать документы до тех пор, пока в кластере осталось хотя бы N/2+1 машин. С точки зрения диагностики потенциальных проблем этот вариант для нас тоже был предпочтительным, так как будучи встраиваемой БД мы знали что сможем контролировать гораздо больше аспектов её поведения. К тому же, так как система реализовывалась на Java, Berkeley DB JE был удобен еще и с точки зрения стоимости тестирования.&lt;/p&gt;

&lt;h2 id=&quot;section-6&quot;&gt;Архитектура поисковой системы&lt;/h2&gt;

&lt;p&gt;С высоты птичьего полета наша поисковая система выглядит следующим образом.&lt;/p&gt;

&lt;p class=&quot;image photo&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/search-architecture/overview.png&quot; alt=&quot;Overview&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Полупрозрачным цветом обозначены звенья системы, количество которых может быть подобрано исходя из нагрузки.&lt;/p&gt;

&lt;p&gt;Основные роли:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Index Node (IN) — машины, выполняющие запросы над инвертированным индексом, группируются в партиции (Apache Lucene);&lt;/li&gt;
  &lt;li&gt;Index Master (IM) — машина, обновляющая инвертированный индекс;&lt;/li&gt;
  &lt;li&gt;Document Storage (DS) — машины занимающиеся хранением исходных документов (Berkeley DB);&lt;/li&gt;
  &lt;li&gt;Coordinator (CN) — машины, являющиеся фасадом к поисковой системе для клиентов. Они инициируют и координируют деятельность внутри кластера, связанную с обработкой пользовательского запроса (REST-сервис);&lt;/li&gt;
  &lt;li&gt;Notification Broker — система обмена сообщениями, которая используется нами для синхронизации состояния кластера (ActiveMQ)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Возможность transactional и data масштабирования мы реализовали путем партиционирования индекса на несколько частей и поддержанием нескольких реплик для каждой партции. Весь индекс разбивается на не пересекающиеся куски примерно одинакового размера. Каждый кусок отдается на обработку отдельной партиции. Партиция состоит из нескольких машин (реплик), которые хранят копию одной и той же части индекса и обрабатывают пользовательские запросы над этой частью индекса.&lt;/p&gt;

&lt;p&gt;Таким образом, когда у нас появляются проблемы с транзакционной нагрузкой, мы добавляем реплики в партиции. Когда появляются проблемы с тем, что одна машина не способна эффективно обрабатывать имеющийся у нее индекс из за того что он слишком большой, мы добавляем новую партицию. При добавлении новой партиции индекс переразбивается на большее количество частей, и каждая партиция получает индекс меньшего размера.&lt;/p&gt;

&lt;h3 id=&quot;section-7&quot;&gt;Поиск&lt;/h3&gt;
&lt;p&gt;Index Node&amp;rsquo;ы делают всю грязную работу, связанную с поиском. У них есть доступ к индексу, а наружу они предоставляют довольно простой интерфейс. На вход от координаторов они принимают детализированный поисковый запрос (в Lucene-формате), параметры сортировки и фасетирования, а на выходе возвращают Top N документов удовлетворяющих запросу. Такой простой интерфейс позволяет реализовывать различные поисковые сценарии, не меняя контракт взаимодействия с Index Node.&lt;/p&gt;

&lt;p class=&quot;image photo&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/search-architecture/communication.png&quot; alt=&quot;Overview&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Index Node&amp;rsquo;ы периодически реплицируют индекс с Index Master&amp;rsquo;а, проверяют его целостность и делают его основным индексом, по которому выполняются поиски.&lt;/p&gt;

&lt;p&gt;Еще одна важная деталь касающаяся Index Node&amp;rsquo;ов заключается в том, что мы разогреваем индекс перед тем как опубликовать его. Каждый Index Node имеет доступ к live потоку текущих запросов. Перед тем как пустить поисковые запросы на новый индекс, по индексу прогоняются production-запросы до тех пор, пока время ответа на этом индексе не стабилизируется. Это защищает пользователей от проблем &amp;ldquo;холодного индекса&amp;rdquo;. То же самое происходит при старте индексных машин.&lt;/p&gt;

&lt;p class=&quot;image photo&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/search-architecture/warmup.png&quot; alt=&quot;Warm up индекса&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Всем процессом поиска управляют координаторы, которые тоже резервируются. При поиске координатор выбирает по одной реплике из каждой партиции и передает запрос им. После того как реплики ответят, координатор объединяет частичные результаты, полученные от реплик, выполняет пейджинг, получает необходимые документы из БД и отдает ответ клиенту. Координаторы не имеют собственного состояния и содержат всю логику, связанную со сценариями поиска.&lt;/p&gt;

&lt;p&gt;После успешного выполнения запроса, сам запрос публикуется на общую шину для последующей обработки. Примерами такой обработки являются: архивирование логов, упомянутый ранее разогрев индекса и сбор различной статистики.&lt;/p&gt;

&lt;p&gt;Обобщение процесса поиска проиллюстрировано на следующей схеме. Процессы, происходящие асинхронно и не блокирующие обработку поискового запроса, отображены пунктиром.&lt;/p&gt;

&lt;p class=&quot;image photo&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/search-architecture/search-read.png&quot; alt=&quot;Data flow при поиске&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-8&quot;&gt;Обновление индекса и хранение данных&lt;/h3&gt;
&lt;p&gt;Одно из решений которое, отличает нашу систему от open source аналогов вроде Solr, заключается в том, что мы храним не только индекс, но и исходные документы, которые предоставляет клиент на индексацию. Системы же вроде Solr на выходе выдают дают набор идентификаторов, и вы должны дополнительно преобразовать их в данные, которые собираетесь показать пользователю.&lt;/p&gt;

&lt;p&gt;В качестве БД мы используем Berkeley DB Java Edition. Это key-value log-oriented база данных. Так как она является встраиваемой БД, все данные доступны in-memory, что очень удобно при умеренных размерах корпуса документов. Нагрузочное тестирование показало, что на корпусе в 50 миллионов документов BDB не является узким звеном и отлично справляется со своими задачами.&lt;/p&gt;

&lt;p&gt;На схеме ниже отображен data-flow при записи документа в поисковую службу:&lt;/p&gt;

&lt;p class=&quot;image photo&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/search-architecture/search-write.png&quot; alt=&quot;Data flow при записи&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Berkeley DB периодически рапортует информацию о состоянии кластера координаторам, чтобы те знали, на какую из машин кластера отсылать запросы на запись.&lt;/p&gt;

&lt;p&gt;Обновляется индекс отдельной машиной кластера – Index Master&amp;rsquo;ом. Структура инвертированого индекса сильно оптимизирована под эффективное чтение, поэтому его обновление операция относительно не дешёвая. В задачи Index Master&amp;rsquo;а входит:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;обновление инвертированного индекса в соответствии с поступающими на индексацию документами и топологией кластера (количеством партиций и их конфигурацией);&lt;/li&gt;
  &lt;li&gt;поддержание индекса в компактном состоянии для минимизации накладных расходов поисковых реплик.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Именно Index Master определяет в какую партицию попадет какой документ.&lt;/p&gt;

&lt;p class=&quot;image photo&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/search-architecture/im-partitions.png&quot; alt=&quot;Взаимодействие Index Master и партиций&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-9&quot;&gt;Проблемы и компромиссы&lt;/h2&gt;

&lt;p&gt;Рассказ был бы неполный, если бы я не упомянул о проблемах, с которыми нам пришлось столкнуться, и о компромиссах на которые нам пришлось пойти.&lt;/p&gt;

&lt;p&gt;Одно из спорных решений, которое мы приняли заключается в том, что мы равномерно распределяем документы по партициям кластера на основании идентификатора документа&lt;sup id=&quot;fnref:ref-ii-partitionong&quot;&gt;&lt;a href=&quot;#fn:ref-ii-partitionong&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;. Плюс этого подхода заключается, в том что мы получаем очень равномерное распределение документов и запросов, а следственно и нагрузки, между партициями. Минус же заключается в том, что этот подход не дает абсолютно никакой локализации (data locality). На фазе поиска мы не можем сделать никаких предположений о том, где расположены целевые документы, поэтому мы вынуждены опрашивать все партиции и делать scatter-gather. Это вызывает ряд неудобств.&lt;/p&gt;

&lt;p&gt;Первое неудобство заключается в том, что координатор вынужден ждать ответа от всех партиций. Соответственно, общая производительность системы ограничивается производительностью самой медленной партиции. В случае большого количества партиций, производительность отдельной партиции может существенно отличаться от производительности системы в целом.&lt;/p&gt;

&lt;p class=&quot;image&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/search-architecture/cdf-latency.png&quot; alt=&quot;CDF времени ответа для систем с различным количеством партиций&quot; width=&quot;467&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Как видно, чем больше партиций, тем ниже производительность. Если каждая отдельная партиция с вероятностью 25% отвечает за 100 миллисекунд, то система, ждущая ответа 4-х партиций, не сможет отвечать за 100 миллисекунд в 25% случаев. Следует сказать, что этот вывод основывается на предположении взаимной независимости времени ответа между партициями, что далеко не всегда является правдой. Но в распределенных системах к этому качеству всячески стремятся, так как оно полезно во многих контекстах.&lt;/p&gt;

&lt;p&gt;Также, scatter-gather на большое количество партиций при определенных обстоятельства может приводить к моментальному выеданию сетевого канала и/или TCP-incast&amp;rsquo;у&lt;sup id=&quot;fnref:ref-tcp-incast&quot;&gt;&lt;a href=&quot;#fn:ref-tcp-incast&quot; rel=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;. Суть в следующем: пейджинг можно делать только после того, как объединены поисковые результаты всех партиций. Поэтому Index Node не может делать пейджинг на своей стороне и вынужден отсылать на координатор не только страницу с запрошенными результатами, но и все документы, предшествующие ей. Таким образом, если человек запросил 1000-ую страницу, а на каждой странице по 100 документов, то каждая партиция должна отослать на координатор 100 000 совпавших документов. Легко посчитать, что при среднем размере записи в 30 байт на документ (вместе с идентификатором возвращается служебная информация) и при 10 партициях суммарный размер ответа будет близок к 30 мегабайтам. В худшем случае это означает прибавку к latency в сотни миллисекунд (на гигабитном канале) и не более 4-5 запросов в секунду на одной машинке.&lt;/p&gt;

&lt;p&gt;С другой стороны, польза от просмотра 1000-ой страница довольно сомнительная. По нашей статистике до 10-й страницы доходит менее одного процента пользователей. Поэтому выход из этой ситуации для нас был очень простой, – мы просто не обслуживаем запросы дальше определенной страницы. Такое же поведение вы можете заметить у многих других систем (Яндекс, Google, eBay).&lt;/p&gt;

&lt;p&gt;Еще одна причина, почему мы решили не заморачиваться с data locality, состоит в том, что в противном случае нам пришлось бы самим реализовывать Distributed IDF для Lucene&lt;sup id=&quot;fnref:ref-distributed-idf&quot;&gt;&lt;a href=&quot;#fn:ref-distributed-idf&quot; rel=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;. В общих чертах, IDF — это статистическая информация по корпусу документов, которая используется для ранжирования. В случае если документы распределяются равновероятно между партициями, а не на основании их контента, мы считаем что локальный IDF партиции является приемлемой апроксимацией глобального IDF.&lt;/p&gt;

&lt;p&gt;Вообще, схема оптимального разбиения корпуса документов – это отдельная очень большая и интересная тема, которую я не могу осветить сейчас.&lt;/p&gt;

&lt;h2 id=&quot;section-10&quot;&gt;Полученные результаты&lt;/h2&gt;

&lt;p&gt;Описанная в данной заметке система работает уже около полугода, и у нас появился эксплуатационный опыт, позволяющий судить о ее качествах. Немного цифр:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;транзакционная нагрузка (номинальная 300 tps, пиковая 1000 tps, 17 миллионов запросов в сутки);&lt;/li&gt;
  &lt;li&gt;размер текущего корпуса документов — 8 миллионов;&lt;/li&gt;
  &lt;li&gt;пропускная способность индексации — 1000 документов в секунду;&lt;/li&gt;
  &lt;li&gt;время ответа: среднее — 50ms, 9-й дециль — 150ms.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Система горизонтально масштабируется по размеру корпуса. Мы это проверили на практике, за последние пол года он вырос более чем в два раза. Добавление новых партиций позволило держать время ответа системы стабильным, не отвлекая от работы разработчиков.&lt;/p&gt;

&lt;p&gt;Результаты capacity-тестирования говорят, что с минорными изменениями система способна обеспечить приемлемое время ответа на корпусе в 50 миллионов документов. По нашим оценкам, это дает нам около года спокойной работы без оглядки на проблемы с производительностью поиска, что нас вполне устраивает.&lt;/p&gt;

&lt;h2 id=&quot;section-11&quot;&gt;Ссылки по теме&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:ref-solr-stored-performance&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://wiki.apache.org/solr/SolrPerformanceFactors#stored_fields&quot;&gt;Solr Performance Factors&lt;/a&gt;&lt;a href=&quot;#fnref:ref-solr-stored-performance&quot; rel=&quot;reference&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:ref-sphinx-distributed-search&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://sphinxsearch.com/docs/1.10/distributed.html&quot;&gt;Sphinx Documentation: Distributed Searching&lt;/a&gt;&lt;a href=&quot;#fnref:ref-sphinx-distributed-search&quot; rel=&quot;reference&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:ref-solr-distributed-search&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://wiki.apache.org/solr/DistributedSearch#Distributed_Indexing&quot;&gt;Solr Distributed Indexing&lt;/a&gt;&lt;a href=&quot;#fnref:ref-solr-distributed-search&quot; rel=&quot;reference&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:ref-ii-partitionong&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.62.1613&quot;&gt;Effect of Inverted Index Partitioning Schemes on Performance of Query Processing in Parallel Text Retrieval Systems&lt;/a&gt;&lt;a href=&quot;#fnref:ref-ii-partitionong&quot; rel=&quot;reference&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:ref-tcp-incast&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://www.eecs.berkeley.edu/Pubs/TechRpts/2012/EECS-2012-40.pdf&quot;&gt;Understanding TCP Incast and Its Implications for Big Data Workloads&lt;/a&gt;&lt;a href=&quot;#fnref:ref-tcp-incast&quot; rel=&quot;reference&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:ref-distributed-idf&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://lucene.472066.n3.nabble.com/solrCloud-Distributed-IDF-scoring-in-the-cloud-td2526179.html&quot;&gt;Solr Mailing Lists: Distributed IDF - scoring in the cloud&lt;/a&gt;&lt;a href=&quot;#fnref:ref-distributed-idf&quot; rel=&quot;reference&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Линейный счетчик</title>
      <link>http://bazhenov.me/blog/2012/12/12/linear-counter.html</link>
      <pubDate>Wed, 12 Dec 2012 00:00:00 +1100</pubDate>
      <author>Denis Bazhenov (dotsid@gmail.com)</author>
      <guid isPermaLink="true">http://bazhenov.me/blog/2012/12/12/linear-counter.html</guid>
      <description>&lt;p&gt;Допустим, вам необходимо рассчитать количество уникальных строк в файле. Причем, файл большой – миллионы или десятки миллионов строк. Типичный shell&amp;rsquo;овский однострочник который позволяет решить эту задачу выглядит следующим образом:&lt;/p&gt;

&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;sort | uniq | wc -l
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;И все бы хорошо, но есть одна проблема. Имя ей &lt;code&gt;sort&lt;/code&gt;.&lt;/p&gt;

&lt;!-- excerpt --&gt;

&lt;p&gt;Сортировка &lt;script type=&quot;math/tex&quot;&gt;O(n \log n)&lt;/script&gt; по времени и &lt;script type=&quot;math/tex&quot;&gt;O(n)&lt;/script&gt; по памяти, поэтому время её работы очень быстро перерастает все разумные пределы. Как вариант, можно хранить не сами строки, а их контрольные суммы. Это снизит как требования по памяти, так и асимптотическую оценку по времени до &lt;script type=&quot;math/tex&quot;&gt;O(n)&lt;/script&gt;. Но хранение контрольных сумм подразумевает наличие коллизий, поэтому вы можете получить не точную оценку, а приблизительную. В случаях когда приблизительной оценки достаточно мы можем разменять точность алгоритма на его скорость и требования к памяти.&lt;/p&gt;

&lt;p&gt;Существует один очень простой алгоритм который позволяет вычислять оценку количества уникальных объектов в потоке с довольно высокой точностью за линейное время, используя &lt;em&gt;0.1 бита на один уникальный объект&lt;/em&gt;. Да да, вы не ослышались в одном бите хранится информация о десяти уникальных объектах.&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;Алгоритм линейного счетчика&lt;/h2&gt;

&lt;p&gt;Ладно, я вас обманул. Невозможно в одном бите хранить информацию о десяти объектах. Но можно хранить тот факт что мы уже встречали хотя бы один из объектов привязанных к этому биту. Именно эта идея лежит в основе алгоритма.&lt;/p&gt;

&lt;p&gt;Представьте, что у вас есть битовый вектор из 1000 бит, и вы устанавливаете в нем 1000 случайных бит (некоторые биты будут установлены более одного раза). Если вы теперь посчитаете сколько битов установлено в единицу, то получите число близкое к 630. Если вам интересно почему в итоге получается именно такое число, то об этом &lt;a href=&quot;http://bazhenov.me/blog/2012/04/16/one-in-a-million.html&quot;&gt;я уже писал&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Верно и обратное. Если мы встречаем битовый вектор длины &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; в котором примерно 63% бит установлено в единицу, это значит что надо этим вектором было произведено примерно &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; операций установки бита в единицу, при условии что биты выбирались равновероятно.&lt;/p&gt;

&lt;p&gt;Таким, довольно нехитрым, способом можно восстановить оценку количества уникальных объектов на основании population count битового вектора (количества бит установленных в единицу). Сделать это можно используя следующую формулу: &lt;script type=&quot;math/tex&quot;&gt; l \log(\frac{l}{N_f}) &lt;/script&gt;, где &lt;script type=&quot;math/tex&quot;&gt;l&lt;/script&gt; — длина вектора, а &lt;script type=&quot;math/tex&quot;&gt;N_f&lt;/script&gt; количество свободных (нулевых) бит (логарифм обязан быть натуральным).&lt;/p&gt;

&lt;p&gt;На графике ниже приведена &lt;a href=&quot;https://gist.github.com/4267208&quot;&gt;симуляция&lt;/a&gt; для вектора длины 10000. В него индексировалось указанное количество объектов, затем получалась доля установленных бит и на её основании восстанавливалась оценка количества добавленных объектов.&lt;/p&gt;

&lt;p class=&quot;image&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/linear-counter/fig1.png&quot; alt=&quot;Тестирование линейного счетчика&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Точность оценки естественным образом связана с отношением количества уникальных объектов к длине битового вектора. Оказывается, что даже если количество добавляемых объектов превышает длину вектора в десять раз, вы по-прежнему можете получать достаточно точные оценки. Погрешность при этом составляет порядка 1%. Это означает, что если в потоке 100 миллионов уникальных объектов, для получения более менее приемлемой оценки достаточно 10 мегабайт памяти.&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;Реализация&lt;/h2&gt;

&lt;p&gt;Реализация этого алгоритма довольно простая. Самое главное, это хеш-функция с равномерным распределением. Любая криптографическая функция вполне подойдет.&lt;/p&gt;

&lt;p&gt;Консольная утилита способная делать быстрый estimate количества уникальных строк в pipe&amp;rsquo;е иногда очень кстати. Поэтому, я реализовал &lt;a href=&quot;https://github.com/bazhenov/linear-counter&quot;&gt;линейный счетчик на C++&lt;/a&gt;. Вы можете использовать этот код в качестве примера. Если же вы пишете на Java, то есть замечательный проект &lt;a href=&quot;https://github.com/clearspring/stream-lib&quot;&gt;stream-lib&lt;/a&gt; в котором помимо линейного счетчика есть масса других вероятностных алгоритмов которые могут оказаться очень полезными при работе с большими массивами данных.&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;Ссылки по теме&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Kyu Y. Whang, Brad T. Vander Zanden, and Howard M. Taylor. &lt;a href=&quot;http://dblab.kaist.ac.kr/Publication/pdf/ACM90_TODS_v15n2.pdf&quot;&gt;A linear-time probabilistic counting algorithm for database applications.&lt;/a&gt; ACM Trans. Database Syst., 15(2):208–229, 1990;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://highlyscalable.wordpress.com/2012/05/01/probabilistic-structures-web-analytics-data-mining/&quot;&gt;Probabilistic Data Structures for Web Analytics and Data Mining&lt;/a&gt; — Ilya Katsov.&lt;/li&gt;
&lt;/ul&gt;

</description>
    </item>
    
    <item>
      <title>Feature selection в алгоритмах классификации</title>
      <link>http://bazhenov.me/blog/2012/12/10/feature-selection.html</link>
      <pubDate>Mon, 10 Dec 2012 00:00:00 +1100</pubDate>
      <author>Denis Bazhenov (dotsid@gmail.com)</author>
      <guid isPermaLink="true">http://bazhenov.me/blog/2012/12/10/feature-selection.html</guid>
      <description>&lt;p&gt;Существует один очень простой и эффективный способ улучшения алгоритмов классификации, который называется &lt;a href=&quot;http://en.wikipedia.org/wiki/Feature_selection&quot;&gt;feature selection&lt;/a&gt; (выбор классификационных признаков). Этот метод позволяет при построении модели выбрать только самые показательные признаки (например, слова) и отсеять остальные.&lt;/p&gt;

&lt;!-- excerpt --&gt;

&lt;p&gt;Что такое показательные признаки? Если мы говорим о задаче классификации текстовых документов, то это слова которые несут информацию о классе к которому относится документ. Например, в контексте автомобильной тематики слово &amp;ldquo;Nissan&amp;rdquo;, скорее всего будет показательным признаком, а вот слово &amp;ldquo;новый&amp;rdquo; вряд ли. Использование для классификации не всех слов, а только показательных дает несколько преимуществ.&lt;/p&gt;

&lt;p&gt;Во-первых, feature selection позволяет существенно уменьшить количество параметров модели (используемых для классификации слов), и как следствие снижает требования к объему памяти требуемой для классификации.&lt;/p&gt;

&lt;p&gt;Во-вторых, feature selection может повысить точность алгоритма за счет удаления из модели слов с низким соотношением сигнал/шум. Представьте, что слово &amp;ldquo;аскетичный&amp;rdquo; встретилось в обучающей выборке 3 раза, – 1 раз в рамках класса &amp;ldquo;Авто&amp;rdquo; и 2 раза в рамках класса &amp;ldquo;Одежда&amp;rdquo;. Формально оно говорит в пользу класса &amp;ldquo;Одежда&amp;rdquo;, но вряд ли это слово можно считать хорошим классификационным признаком. Скорее всего, перевес в сторону одежды это случайность.&lt;/p&gt;

&lt;p&gt;Но &lt;em&gt;сам факт наличия такого слова в обучающей выборке не случайность&lt;/em&gt;. Это следствие &lt;a href=&quot;http://ru.wikipedia.org/wiki/Закон_Ципфа&quot;&gt;закона Зипфа&lt;/a&gt; (Zipf&amp;rsquo;s law), который описывает распределение частот слов в натуральном языке. Простым языком это можно описать следующим образом, если вы возьмете любой достаточно большой корпус документов и посчитаете сколько в нем слов встречающихся ровно 1 раз, 2 раза, 3 раза и т.д., то окажется что большинство слов встречаются 1 раз. Это не должно быть большим сюрпризом, – в повседневной жизни мы используем довольно небольшое количество слов (высокочастотники), а большую часть слов мы практически не используем (низкочастотники).&lt;/p&gt;

&lt;h2 id=&quot;mutual-information&quot;&gt;Mutual Information&lt;/h2&gt;

&lt;p&gt;В этой заметке я опишу один, пожалуй самый простой способ оценки показательности классификационных признаков, – &lt;a href=&quot;http://nlp.stanford.edu/IR-book/html/htmledition/mutual-information-1.html&quot;&gt;метод взаимной информации&lt;/a&gt; (Mutual Information). Идея метода очень проста. Зная как часто слово употребляется в пределах документов класса и за его пределами, мы можем сказать насколько статистически сильно связаны слово и класс.&lt;/p&gt;

&lt;p&gt;Для того чтобы рассчитать численное значение взаимной информации необходимо составить матрицу цитирумости. Матрица цитируемости – это матрица 2x2 которая показывает взаимоотношение конкретного слова с конкретным классов. Возьмем, к примеру слово &amp;ldquo;Toyota&amp;rdquo; и класс &amp;ldquo;Авто&amp;rdquo;.&lt;/p&gt;

&lt;table align=&quot;center&quot;&gt;
	&lt;tr&gt;
		&lt;th /&gt;
		&lt;th&gt;C&lt;sub&gt;Авто&lt;/sub&gt;=1&lt;/th&gt;
		&lt;th&gt;C&lt;sub&gt;Авто&lt;/sub&gt;=0&lt;/th&gt;
	&lt;/tr&gt;
	&lt;tr&gt;
		&lt;th&gt;W&lt;sub&gt;Toyota&lt;/sub&gt;=1&lt;/th&gt;
		&lt;td&gt;N&lt;sub&gt;11&lt;/sub&gt;=65 342&lt;/td&gt;
		&lt;td&gt;N&lt;sub&gt;10&lt;/sub&gt;=143&lt;/td&gt;
	&lt;/tr&gt;
	&lt;tr&gt;
		&lt;th&gt;W&lt;sub&gt;Toyota&lt;/sub&gt;=0&lt;/th&gt;
		&lt;td&gt;N&lt;sub&gt;01&lt;/sub&gt;=45 342&lt;/td&gt;
		&lt;td&gt;N&lt;sub&gt;00&lt;/sub&gt;=897 657&lt;/td&gt;
	&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;Из этой матрицы видно что слово &amp;ldquo;Toyota&amp;rdquo; было встречено в 65 342 документах в контексте класса &amp;ldquo;Авто&amp;rdquo;, а также в 143 документах за переделами класса &amp;ldquo;Авто&amp;rdquo;. Имея на руках такую матрицу мы можем рассчитать взаимную информацию по формуле:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt; MI =
\frac{N_{11}}{N} \log_2{ \frac{N N_{11}}{N_{1.} N_{.1}} } +
\frac{N_{01}}{N} \log_2{ \frac{N N_{01}}{N_{0.} N_{.1}} } + 
\frac{N_{10}}{N} \log_2{ \frac{N N_{10}}{N_{1.} N_{.0}} } +
\frac{N_{00}}{N} \log_2{ \frac{N N_{00}}{N_{0.} N_{.0}} } &lt;/script&gt;

&lt;p&gt;где, &lt;script type=&quot;math/tex&quot;&gt; N &lt;/script&gt; — сумма всей матрицы, &lt;script type=&quot;math/tex&quot;&gt; N_{0.} = N_{00} + N_{01} &lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt; N_{.1} = N_{01} + N_{11} &lt;/script&gt; и т.д.&lt;/p&gt;

&lt;p&gt;Взаимная информация всегда находится в диапазоне от нуля до единицы. Чем выше значение, тем сильнее связь между наличием/отсутствием слова и наличием/отсутствием класса. Рассчитав взаимную информацию для всех пар слово-класс мы можем оставить для каждого класса первые N слов, объединить эти слова в общий словарь и теперь только их использовать для классификации. Количество слов необходимых для оптимальной классификации зависит от конкретной задачи и его необходимо подбирать эмпирически, постоянно проверяя результаты на тестовой выборке.&lt;/p&gt;

&lt;p&gt;На тех задач на которых я тестировал этот метод, он давал прирост точности от 3 до 10%. В Introduction to Infromation Retrieval указано что на практике возможен прирост в десятки процентов по F&lt;sub&gt;1&lt;/sub&gt;&lt;sup id=&quot;fnref:ref-mi-performance&quot;&gt;&lt;a href=&quot;#fn:ref-mi-performance&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. Все зависит от вашей конкретной задачи, а также классификационного алгоритма.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:ref-mi-performance&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://nlp.stanford.edu/IR-book/html/htmledition/mutual-information-1.html#fig:mccallum&quot;&gt;Introduction to Information Retrieval, 2008 Cambridge University Press&lt;/a&gt;&lt;a href=&quot;#fnref:ref-mi-performance&quot; rel=&quot;reference&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Толерантный автокомплит</title>
      <link>http://bazhenov.me/blog/2012/08/04/autocomplete.html</link>
      <pubDate>Sat, 04 Aug 2012 00:00:00 +1100</pubDate>
      <author>Denis Bazhenov (dotsid@gmail.com)</author>
      <guid isPermaLink="true">http://bazhenov.me/blog/2012/08/04/autocomplete.html</guid>
      <description>&lt;p&gt;Автокомплит вещь удобная. Он позволяет экономить время на наборе текста, когда множество значений поля закрыто. Хороший автокомплит отличается следующими качествами:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;он должен быть быстрый. Если мы хотим экономить силы пользователя, то мы должны ему предложить вариант как можно быстрее;&lt;/li&gt;
  &lt;li&gt;он не должен предлагать к вводу варианты которые заведомо неверны;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;он должен быть толерантен к пользовательскому вводу&lt;/em&gt;. В том числе прощать опечатки.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Вот о последнем качестве autocomplete алгоритмов я и хочу сегодня поговорить.&lt;/p&gt;

&lt;!-- excerpt --&gt;

&lt;p&gt;Если вы хотите создать приложение толерантное к вводимой пользователем информации, то исправление опечаток в том или ином виде должно быть. Человек может опечататься в первой букве, может попросту не знать как правильно пишется слово. Поэтому, не очень хорошо что первая же неверно введенная пользователем буква приведет к тому что он не сможет выбрать правильный вариант.&lt;/p&gt;

&lt;p&gt;Я значительную часть рабочего дня провожу в IntelliJ IDEA. Отличная среда, пожалуй лучшая. А еще, я &lt;a href=&quot;http://bazhenov.me/blog/2012/05/12/functional-java.html&quot;&gt;использую guava&lt;/a&gt;, хорошая библиотека. И есть там такой метод &lt;code&gt;Closeables.closeQuietly()&lt;/code&gt;, который закрывает &lt;code&gt;Closeable&lt;/code&gt; объект подавляя все исключения. Так вот, когда вы пишете имя метода которого нет в текущем классе, IDEA автоматически предлагает вам сделать &lt;code&gt;static import&lt;/code&gt; подходящего метода из других классов.&lt;/p&gt;

&lt;p class=&quot;image photo&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/autocomplete/idea-good.png&quot; alt=&quot;IntelliJ IDEA static import&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Прекрасная фича, которая не работает если вы опечатались. А я ну никак не могу запомнить как правильно пишется слово &amp;ldquo;quietly&amp;rdquo;.&lt;/p&gt;

&lt;p class=&quot;image photo&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/autocomplete/idea-bad.png&quot; alt=&quot;IntelliJ IDEA static import reject&quot; /&gt;&lt;/p&gt;

&lt;p&gt;В этом случае IDE &amp;ldquo;фейлит&amp;rdquo; и предлагает мне создать новый метод. Примерно то же самое происходит и с автодополнением. Стоит мне ввести хотя бы один не тот символ, как тут же &amp;ldquo;No suggestions&amp;rdquo;. Я считаю, IDEA могла бы быть гораздо более толерантна к девелоперу на этапе ввода кода. Это же не какой-нибудь там NetBeans :)&lt;/p&gt;

&lt;p&gt;Этой же проблемой страдает большое количество продуктов.&lt;/p&gt;

&lt;p class=&quot;image photo&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/autocomplete/mac-help.png&quot; alt=&quot;Mac OS X Help Search&quot; /&gt;&lt;/p&gt;
&lt;p class=&quot;description&quot;&gt;Встроенный в Mac OS X поиск по позиция системного меню&lt;/p&gt;

&lt;p class=&quot;image photo&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/autocomplete/mac-spotlight.png&quot; alt=&quot;Mac OS X Spotlight Search&quot; /&gt;&lt;/p&gt;
&lt;p class=&quot;description&quot;&gt;Mac OS X Spotlight&lt;/p&gt;

&lt;p class=&quot;image photo&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/autocomplete/money.png&quot; alt=&quot;Money&quot; /&gt;&lt;/p&gt;
&lt;p class=&quot;description&quot;&gt;Money — ПО для учета персональных финансов&lt;/p&gt;

&lt;p&gt;Такая ситуация выглядит для меня довольно странно, так как алгоритмы позволяющие разруливать большую часть опечаток при вводе довольно банальны.&lt;/p&gt;

&lt;p&gt;Конечно, разработка первоклассного spellchecker&amp;rsquo;а дело не простое. Оно требует обучения не тривиальных статистических моделей. Но есть несколько простых подходов, которые позволяют в большинстве приложений сделать автокомплит достаточно толерантным, чтобы пользователи были счастливы в 80% случаев.&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;Подход №1: Редакционное расстояние&lt;/h2&gt;

&lt;p&gt;Самое простое решение заключается в том чтобы сортировать все позиции словаря по возрастанию редакционного расстояния и показывать только первые несколько позиций. В качестве редакционного расстояния можно взять &lt;a href=&quot;http://ru.wikipedia.org/wiki/Расстояние_Левенштейна&quot;&gt;расстояние Левенштейна&lt;/a&gt;. Расстояние Левенштейна – это минимальное количество операций вставок/удаления/изменения символов необходимое для того чтобы преобразовать исходную строку в целевую.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Список слов близких к слову &amp;ldquo;пазор&amp;rdquo; и их редакционные расстояния: позор &amp;rarr; 1, позер &amp;rarr; 2, дозор &amp;rarr; 2, помор &amp;rarr; 2, побор &amp;rarr; 2, подзор &amp;rarr; 2, покер &amp;rarr; 3, покос &amp;rarr; 3.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Существует статистика что в пределах расстояния Левенштейна 2 находится более 90% опечаток, так что можно показывать только их, чтобы избежать совсем уж неадекватных исправлений.&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;Достоинства&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;довольно проста в реализации. Имплементацию расчёта расстояния Левенштейна можно найти практически для любого языка программирования.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-2&quot;&gt;Недостатки&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Довольно ресурсоемкая. Алгоритмическая сложность алгоритма O(n&lt;sup&gt;2&lt;/sup&gt;). Если в вашем словаре много позиций или у вас много посетителей на данное решение может не хватить аппаратных ресурсов.&lt;/li&gt;
  &lt;li&gt;в данном виде этот подход не позволяет использовать знания о языковой модели, что не дает корректно исправлять некоторые типичные опечатки. Например опечатка &amp;ldquo;corola&amp;rdquo; находится на расстоянии 1 и от &amp;ldquo;corolla&amp;rdquo; и от &amp;ldquo;corona&amp;rdquo;, соответственно две эти замены будут равновероятны. Но пропуск дублирующей &amp;ldquo;l&amp;rdquo; гораздо более вероятная опечатка чем замена &amp;ldquo;l&amp;rdquo; на &amp;ldquo;n&amp;rdquo;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;В целом, решение на основании расстояния Левенштейна будет вполне сносно работать в первом приближении. Его очень просто реализовать, что делает данный подход отличным кандидатом на роль прототипа.&lt;/p&gt;

&lt;h2 id=&quot;k-gram-&quot;&gt;Подход №2: Коэффициент Жаккара и K-gram индекс&lt;/h2&gt;

&lt;p&gt;Альтернативный подход заключается в том чтобы использовать &lt;a href=&quot;http://ru.wikipedia.org/wiki/Коэффициент_Жаккара&quot;&gt;коэффициент Жаккара&lt;/a&gt; как метрику расстояния между строками. Коэффициент Жаккара (Jaccard index) это индекс сходства двух множеств который определяется как отношение мощности пересечения этих множеств к мощности их объединения.&lt;/p&gt;

&lt;p class=&quot;image&quot;&gt;&lt;img src=&quot;http://bazhenov.me/images/autocomplete/sets.png&quot; alt=&quot;Sets&quot; /&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt; J = \frac{\mid A \cap B \mid} {\mid A \cup B \mid} &lt;/script&gt;

&lt;p&gt;При коэффициенте Жаккара равном 1 множества равны, при 0 не имеют ни одного общего элемента. Эту метрику можно использовать для оценки близости вводимых пользователем слов к словам из нашего словаря по которому мы делаем autocomplete.&lt;/p&gt;

&lt;p&gt;Но для того чтобы иметь возможность расчитать коэффициент Жаккара для двух строк нам надо преобразовать их в множества. Самый простой вариант, разбить строку на символы. Но обычно берут не символы строки, а k-граммы строки (также известны как n-граммы). &lt;a href=&quot;http://en.wikipedia.org/wiki/N-gram&quot;&gt;K-грамма&lt;/a&gt; – это непрерывная уникальная последовательность из k символов строки. Дублирующие k-граммы пропускают. Например, в слове &amp;ldquo;клоун&amp;rdquo; 3 триграммы (k = 3): &amp;ldquo;кло&amp;rdquo;, &amp;ldquo;лоу&amp;rdquo; и &amp;ldquo;оун&amp;rdquo;. На практике, k выбирают равным в диапазоне от двух до четырех, в зависимости от характера данных.&lt;/p&gt;

&lt;p&gt;Cформировав из строк множество k-грамм, мы можем расчитать коэффициент Жаккара между этими строками. Например, триграммный коэффициент Жаккара для пары &amp;ldquo;corolla&amp;rdquo; и &amp;ldquo;corola&amp;rdquo; будет выше, чем для пары &amp;ldquo;corona&amp;rdquo; и &amp;ldquo;corola&amp;rdquo;. В первом случае совпадают три триграммы: &amp;ldquo;cor&amp;rdquo;, &amp;ldquo;oro&amp;rdquo; и &amp;ldquo;rol&amp;rdquo;, а во втором случае только две: &amp;ldquo;cor&amp;rdquo; и &amp;ldquo;oro&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;В контексте алгоритма автодополнения, для того чтобы иметь возможность быстро подбирать кандидатов на пользователский запрос, необходимо построить &lt;a href=&quot;http://nlp.stanford.edu/IR-book/html/htmledition/k-gram-indexes-for-spelling-correction-1.html&quot;&gt;k-gram индекс&lt;/a&gt; по словарю автодополнения. K-gram индекс это инвертированный индекс из k-граммы в слова содержащие эту k-грамму. K-gram индекс позволяет  быстро находить элементы с наиболее высоким коэффициентом Жаккара предварительно проиндексировав их.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Биграммный индекс (k = 2) для слов: &amp;ldquo;топор&amp;rdquo;, &amp;ldquo;компот&amp;rdquo; и &amp;ldquo;оптом&amp;rdquo; выглядит следующим образом:&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;то &amp;rarr; оптом, топор&lt;/li&gt;
    &lt;li&gt;оп &amp;rarr; оптом, топор&lt;/li&gt;
    &lt;li&gt;по &amp;rarr; компот, топор&lt;/li&gt;
    &lt;li&gt;ор &amp;rarr; топор&lt;/li&gt;
    &lt;li&gt;ко &amp;rarr; компот&lt;/li&gt;
    &lt;li&gt;ом &amp;rarr; компот, оптом&lt;/li&gt;
    &lt;li&gt;мп &amp;rarr; компот&lt;/li&gt;
    &lt;li&gt;от &amp;rarr; компот&lt;/li&gt;
    &lt;li&gt;пт &amp;rarr; оптом&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;Имея k-gramm индекс алгоритм автодополнения сводится к следующим шагам:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;разбить на k-граммы строку введенную пользователем;&lt;/li&gt;
  &lt;li&gt;для каждой k-граммы получить список слов в которых она встречается (posting list);&lt;/li&gt;
  &lt;li&gt;сделать merge posting list&amp;rsquo;ов с подсчетом какое количество раз каждое слово встречается в них. По факту это количество совпавших k-грамм между строкой пользователя и позицией словаря.&lt;/li&gt;
  &lt;li&gt;отсортировать этот список по убыванию количества совпавших k-грамм;&lt;/li&gt;
  &lt;li&gt;вернуть первые N позиций пользователю.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;section-3&quot;&gt;Достоинства&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;данная подход позволяет эффективно находить строки синтаксически близкие к целевой (с максимальным количеством пересекающихся k-грамм). Существенно быстрее чем редакционное расстояние.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-4&quot;&gt;Недостатки&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;как и редакционное расстояние, не позволяет использовать информацию языковой модели, что не позволяет исправлять сложные типы опечаток;&lt;/li&gt;
  &lt;li&gt;более сложна в реализации чем подход с редакционным расстоянием.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;tips--tricks&quot;&gt;Tips &amp;amp; tricks&lt;/h2&gt;

&lt;p&gt;Некоторые замечания которые могут быть полезны, если вы захотите имплементировать толерантный автокомплит.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;K-gram индекс можно хранить в любой удобной для вас inverted index системе. Например, Apache Lucene;&lt;/li&gt;
  &lt;li&gt;подходы №1 и №2 не являются взаимоисключающими. Очень часто K-gram индекс из за его эффективности используют как предварительный фильтр для других, более сложных алгоритмов;&lt;/li&gt;
  &lt;li&gt;может иметь смысл предварительно убирать из текста все символы не несущие смысловой нагрузки. Например, дефисы, слэши и т.д;&lt;/li&gt;
  &lt;li&gt;при построении k-gram из слова/фразы имеет смысл добавить в исходную строку какой-нибудь специальный символ (например, &amp;ldquo;$&amp;rdquo;) на границе слов. Это сделает результаты более точным, за счет дополнительной совпадающей k-граммы на границах.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;e&quot;&gt;В заключениe&lt;/h2&gt;
&lt;p&gt;Мы рассмотрели два основных инструмента которые позволяют находить и исправлять опечатки. Они могут быть использованы как в чистом виде, так и в составе более сложных стратегий автодополнения. Надеюсь, эта информация даст вам общее представление о том как сделать более толерантное к опечаткам автодополнение.&lt;/p&gt;

</description>
    </item>
    
  </channel> 
</rss>