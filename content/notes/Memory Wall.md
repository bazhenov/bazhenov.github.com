---
unsafe: true
title: Memory Wall
url: /notes/memory-wall/
math: true
---
<p></p>
<ul>
<li>Одно из фундаментальных ограничений современной вычислительной техники. Рост производительности CPU выше чем у оперативной памяти. С точки зрения CPU память становится медленней со временем.</li>
<li>
В [1] приведена следующая информация по latency DRAM<ul>
<li><img src="../assets/Screenshot_2021-12-30_at_17.44.26_1640850270764_0.png" alt="Screenshot 2021-12-30 at 17.44.26.png" /></li>
</ul>
</li>
<li>
#Вопрос Почему latency DRAM падает так медленно?<ul>
<li>latency доступа пропорционально объему памяти?</li>
<li>one cell DRAM, в отличии от SRAM, требует наличие емкости. Поэтому, тяжелее разогнать до частоты аналогичной CPU?</li>
</ul>
</li>
<li>
Это ограничение бьет по вычислительными системам разными способами<ul>
<li>все важнее становится предсказуемость доступа к памяти. Если память далеко, до данные оттуда нужно доставлять заранее. Не во всех алгоритмах понятно что нужно заранее</li>
<li>
Растут издержки вытесняющей многозадачности, так как переключение между процессами приводит к большому количеству промахов кеша. ОС вынуждены поддерживать относительно длинный квант времени выделяемый процессу. До тех пор пока процессов мало, это работает хорошо. Но для приложений с большим количеством параллельных процессов concurrency control становится важной частью работы<ul>
<li><div class='quote'><p class='quote-source'><span class='missing-note'>Размер имеет значение</span></p><blockquote>
<p>Normally, to mitigate these costs, OS’s keep time slices at 100-200ms – and as @1GHz, one million CPU cycles corresponds to 1ms, with a 100ms time slice we’re speaking about &lt;1% performance degradation due to thread context switches.</p>
</blockquote>
</div></li>
</ul>
</li>
</ul>
</li>
<li>
Основной способ, которым пытаются побороть эту проблему – иерархическая организация  памяти в которой первые уровни обладают меньшим объемом но большой скоростью<ul>
<li>добавление большего объема кеша в CPU. В долгосрочной перспективе не устойчивое решение, так как при росте объема SRAM памяти растет и время ее адресации.</li>
<li>увеличение пропускной способности памяти</li>
<li>организация вычислений таким образом, чтобы паттерны доступа к памяти были предсказуемы. В частности, веткоризация</li>
</ul>
</li>
<li>[1] – <a href="https://arxiv.org/pdf/1712.08304.pdf">Understanding and Improving the Latency of DRAM-Based Memory Systems</a></li>
</ul>
